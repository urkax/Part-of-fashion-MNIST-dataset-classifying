split train val random seed:2481
RANDOM SEED: 2481
data catagory: train
len of img: 27000
data catagory: val
len of img: 3000
data catagory: test
len of img: 5000
using device: cuda
loading model
~fc: conv1.weight
~fc: bn1.weight
~fc: bn1.bias
~fc: layer1.0.conv1.weight
~fc: layer1.0.bn1.weight
~fc: layer1.0.bn1.bias
~fc: layer1.0.conv2.weight
~fc: layer1.0.bn2.weight
~fc: layer1.0.bn2.bias
~fc: layer1.1.conv1.weight
~fc: layer1.1.bn1.weight
~fc: layer1.1.bn1.bias
~fc: layer1.1.conv2.weight
~fc: layer1.1.bn2.weight
~fc: layer1.1.bn2.bias
~fc: layer2.0.conv1.weight
~fc: layer2.0.bn1.weight
~fc: layer2.0.bn1.bias
~fc: layer2.0.conv2.weight
~fc: layer2.0.bn2.weight
~fc: layer2.0.bn2.bias
~fc: layer2.0.downsample.0.weight
~fc: layer2.0.downsample.1.weight
~fc: layer2.0.downsample.1.bias
~fc: layer2.1.conv1.weight
~fc: layer2.1.bn1.weight
~fc: layer2.1.bn1.bias
~fc: layer2.1.conv2.weight
~fc: layer2.1.bn2.weight
~fc: layer2.1.bn2.bias
~fc: layer3.0.conv1.weight
~fc: layer3.0.bn1.weight
~fc: layer3.0.bn1.bias
~fc: layer3.0.conv2.weight
~fc: layer3.0.bn2.weight
~fc: layer3.0.bn2.bias
~fc: layer3.0.downsample.0.weight
~fc: layer3.0.downsample.1.weight
~fc: layer3.0.downsample.1.bias
~fc: layer3.1.conv1.weight
~fc: layer3.1.bn1.weight
~fc: layer3.1.bn1.bias
~fc: layer3.1.conv2.weight
~fc: layer3.1.bn2.weight
~fc: layer3.1.bn2.bias
~fc: layer4.0.conv1.weight
~fc: layer4.0.bn1.weight
~fc: layer4.0.bn1.bias
~fc: layer4.0.conv2.weight
~fc: layer4.0.bn2.weight
~fc: layer4.0.bn2.bias
~fc: layer4.0.downsample.0.weight
~fc: layer4.0.downsample.1.weight
~fc: layer4.0.downsample.1.bias
~fc: layer4.1.conv1.weight
~fc: layer4.1.bn1.weight
~fc: layer4.1.bn1.bias
~fc: layer4.1.conv2.weight
~fc: layer4.1.bn2.weight
~fc: layer4.1.bn2.bias
 fc: fc.weight
 fc: fc.bias
fc learning rate: 0.001
not fc learning rate: 0.001
ResNet(
  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
epoch: 0
Train: [0/422]	Time 1.604 (1.604)	Loss 9.9303 (9.9303)	Prec@1 21.875 (21.875)	Prec@5 75.000 (75.000)
Train: [50/422]	Time 0.067 (0.088)	Loss 1.5523 (4.3511)	Prec@1 64.062 (45.925)	Prec@5 96.875 (89.461)
Train: [100/422]	Time 0.063 (0.058)	Loss 0.8601 (2.9888)	Prec@1 71.875 (53.047)	Prec@5 100.000 (93.000)
Train: [150/422]	Time 0.062 (0.059)	Loss 0.5469 (1.4614)	Prec@1 81.250 (61.891)	Prec@5 100.000 (96.906)
Train: [200/422]	Time 0.057 (0.060)	Loss 0.7903 (1.0656)	Prec@1 68.750 (66.359)	Prec@5 100.000 (97.812)
Train: [250/422]	Time 0.066 (0.059)	Loss 0.6206 (0.9007)	Prec@1 75.000 (69.953)	Prec@5 98.438 (98.266)
Train: [300/422]	Time 0.069 (0.058)	Loss 0.9384 (0.8068)	Prec@1 59.375 (72.094)	Prec@5 98.438 (98.812)
Train: [350/422]	Time 0.064 (0.060)	Loss 0.8924 (0.7323)	Prec@1 65.625 (73.859)	Prec@5 100.000 (99.109)
Train: [400/422]	Time 0.060 (0.060)	Loss 0.6189 (0.6867)	Prec@1 73.438 (75.375)	Prec@5 100.000 (99.234)
Test: [0/47]	Time 0.317 (0.317)	Loss 0.7247 (0.7247)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Test: [20/47]	Time 0.023 (0.037)	Loss 0.4540 (0.5599)	Prec@1 82.812 (78.646)	Prec@5 100.000 (99.702)
Test: [40/47]	Time 0.009 (0.027)	Loss 1.0199 (0.6177)	Prec@1 78.125 (78.011)	Prec@5 98.438 (99.581)
Test: [0/40] Acc 78.200
epoch: 1
Train: [0/422]	Time 0.350 (0.350)	Loss 0.7277 (0.7277)	Prec@1 70.312 (70.312)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.064)	Loss 0.7193 (0.6278)	Prec@1 76.562 (77.328)	Prec@5 96.875 (99.326)
Train: [100/422]	Time 0.064 (0.059)	Loss 0.7636 (0.6335)	Prec@1 76.562 (77.547)	Prec@5 98.438 (99.391)
Train: [150/422]	Time 0.030 (0.059)	Loss 0.9376 (0.6327)	Prec@1 75.000 (77.500)	Prec@5 95.312 (99.469)
Train: [200/422]	Time 0.062 (0.060)	Loss 0.4929 (0.6236)	Prec@1 81.250 (77.562)	Prec@5 100.000 (99.500)
Train: [250/422]	Time 0.066 (0.060)	Loss 0.6841 (0.6066)	Prec@1 78.125 (77.906)	Prec@5 100.000 (99.516)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.3998 (0.5742)	Prec@1 82.812 (78.188)	Prec@5 98.438 (99.594)
Train: [350/422]	Time 0.061 (0.058)	Loss 0.4090 (0.5510)	Prec@1 82.812 (78.938)	Prec@5 100.000 (99.547)
Train: [400/422]	Time 0.059 (0.059)	Loss 0.3922 (0.5350)	Prec@1 84.375 (80.125)	Prec@5 100.000 (99.422)
Test: [0/47]	Time 0.325 (0.325)	Loss 0.4369 (0.4369)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.036)	Loss 0.3714 (0.4077)	Prec@1 82.812 (84.673)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.028)	Loss 0.6618 (0.4576)	Prec@1 82.812 (83.880)	Prec@5 98.438 (99.619)
Test: [1/40] Acc 83.900
epoch: 2
Train: [0/422]	Time 0.364 (0.364)	Loss 0.6735 (0.6735)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.059 (0.064)	Loss 0.3798 (0.5218)	Prec@1 87.500 (80.545)	Prec@5 100.000 (99.449)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.4517 (0.5192)	Prec@1 81.250 (80.641)	Prec@5 100.000 (99.453)
Train: [150/422]	Time 0.032 (0.059)	Loss 0.5070 (0.5202)	Prec@1 79.688 (80.797)	Prec@5 100.000 (99.547)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.3438 (0.5056)	Prec@1 87.500 (81.438)	Prec@5 100.000 (99.688)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.3845 (0.4844)	Prec@1 84.375 (81.953)	Prec@5 100.000 (99.688)
Train: [300/422]	Time 0.059 (0.058)	Loss 0.4303 (0.4879)	Prec@1 87.500 (82.234)	Prec@5 100.000 (99.672)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.5580 (0.4777)	Prec@1 84.375 (82.422)	Prec@5 100.000 (99.766)
Train: [400/422]	Time 0.044 (0.059)	Loss 0.4459 (0.4853)	Prec@1 84.375 (82.031)	Prec@5 100.000 (99.734)
Test: [0/47]	Time 0.319 (0.319)	Loss 0.3688 (0.3688)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.036)	Loss 0.3277 (0.3531)	Prec@1 85.938 (85.565)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.029)	Loss 0.3618 (0.3969)	Prec@1 87.500 (85.023)	Prec@5 100.000 (99.848)
Test: [2/40] Acc 85.167
epoch: 3
Train: [0/422]	Time 0.354 (0.354)	Loss 0.4048 (0.4048)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.063 (0.063)	Loss 0.4163 (0.4522)	Prec@1 81.250 (83.119)	Prec@5 100.000 (99.694)
Train: [100/422]	Time 0.061 (0.058)	Loss 0.4287 (0.4559)	Prec@1 81.250 (82.797)	Prec@5 100.000 (99.766)
Train: [150/422]	Time 0.037 (0.060)	Loss 0.4145 (0.4548)	Prec@1 84.375 (82.688)	Prec@5 100.000 (99.719)
Train: [200/422]	Time 0.064 (0.060)	Loss 0.5721 (0.4551)	Prec@1 81.250 (83.188)	Prec@5 100.000 (99.578)
Train: [250/422]	Time 0.067 (0.059)	Loss 0.3930 (0.4446)	Prec@1 85.938 (83.531)	Prec@5 100.000 (99.641)
Train: [300/422]	Time 0.055 (0.059)	Loss 0.5722 (0.4337)	Prec@1 84.375 (83.688)	Prec@5 100.000 (99.797)
Train: [350/422]	Time 0.064 (0.059)	Loss 0.6102 (0.4463)	Prec@1 81.250 (83.328)	Prec@5 100.000 (99.797)
Train: [400/422]	Time 0.030 (0.060)	Loss 0.3625 (0.4383)	Prec@1 87.500 (83.516)	Prec@5 98.438 (99.734)
Test: [0/47]	Time 0.337 (0.337)	Loss 0.4392 (0.4392)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.036)	Loss 0.3663 (0.4395)	Prec@1 87.500 (82.812)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.022 (0.029)	Loss 0.3699 (0.4718)	Prec@1 85.938 (82.889)	Prec@5 100.000 (99.809)
Test: [3/40] Acc 83.200
epoch: 4
Train: [0/422]	Time 0.413 (0.413)	Loss 0.3338 (0.3338)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.066)	Loss 0.4148 (0.4161)	Prec@1 82.812 (84.252)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.4176 (0.4239)	Prec@1 82.812 (84.328)	Prec@5 100.000 (99.734)
Train: [150/422]	Time 0.032 (0.060)	Loss 0.3502 (0.4211)	Prec@1 85.938 (84.609)	Prec@5 100.000 (99.703)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.4805 (0.4207)	Prec@1 87.500 (84.344)	Prec@5 100.000 (99.750)
Train: [250/422]	Time 0.069 (0.059)	Loss 0.3492 (0.4240)	Prec@1 84.375 (84.281)	Prec@5 100.000 (99.688)
Train: [300/422]	Time 0.063 (0.058)	Loss 0.8362 (0.4149)	Prec@1 75.000 (84.750)	Prec@5 100.000 (99.703)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.4603 (0.4181)	Prec@1 76.562 (84.344)	Prec@5 100.000 (99.703)
Train: [400/422]	Time 0.041 (0.060)	Loss 0.2632 (0.4072)	Prec@1 84.375 (84.172)	Prec@5 100.000 (99.719)
Test: [0/47]	Time 0.346 (0.346)	Loss 0.3221 (0.3221)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.036)	Loss 0.3317 (0.3266)	Prec@1 87.500 (87.649)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.020 (0.029)	Loss 0.2623 (0.3600)	Prec@1 90.625 (87.271)	Prec@5 100.000 (99.771)
Test: [4/40] Acc 87.300
epoch: 5
Train: [0/422]	Time 0.379 (0.379)	Loss 0.4600 (0.4600)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.4073 (0.3902)	Prec@1 89.062 (85.509)	Prec@5 98.438 (99.724)
Train: [100/422]	Time 0.059 (0.059)	Loss 0.3880 (0.3910)	Prec@1 87.500 (85.250)	Prec@5 100.000 (99.766)
Train: [150/422]	Time 0.032 (0.060)	Loss 0.3919 (0.3918)	Prec@1 85.938 (85.359)	Prec@5 100.000 (99.812)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.2165 (0.3894)	Prec@1 93.750 (85.266)	Prec@5 98.438 (99.750)
Train: [250/422]	Time 0.069 (0.059)	Loss 0.4777 (0.3791)	Prec@1 78.125 (85.625)	Prec@5 100.000 (99.797)
Train: [300/422]	Time 0.064 (0.058)	Loss 0.2189 (0.3730)	Prec@1 92.188 (86.312)	Prec@5 100.000 (99.766)
Train: [350/422]	Time 0.061 (0.059)	Loss 0.4268 (0.3736)	Prec@1 87.500 (85.969)	Prec@5 100.000 (99.797)
Train: [400/422]	Time 0.052 (0.060)	Loss 0.4930 (0.3803)	Prec@1 85.938 (85.609)	Prec@5 100.000 (99.891)
Test: [0/47]	Time 0.333 (0.333)	Loss 0.2852 (0.2852)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.025 (0.036)	Loss 0.3611 (0.3228)	Prec@1 90.625 (87.946)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.023 (0.030)	Loss 0.3160 (0.3598)	Prec@1 90.625 (87.043)	Prec@5 100.000 (99.886)
Test: [5/40] Acc 87.167
epoch: 6
Train: [0/422]	Time 0.374 (0.374)	Loss 0.3289 (0.3289)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.2901 (0.3536)	Prec@1 90.625 (86.642)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.031 (0.060)	Loss 0.1724 (0.3568)	Prec@1 96.875 (86.531)	Prec@5 100.000 (99.844)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.2417 (0.3600)	Prec@1 89.062 (86.625)	Prec@5 100.000 (99.875)
Train: [200/422]	Time 0.028 (0.054)	Loss 0.3087 (0.3690)	Prec@1 89.062 (86.266)	Prec@5 100.000 (99.781)
Train: [250/422]	Time 0.068 (0.042)	Loss 0.3101 (0.3663)	Prec@1 85.938 (86.328)	Prec@5 100.000 (99.719)
Train: [300/422]	Time 0.061 (0.047)	Loss 0.2157 (0.3608)	Prec@1 90.625 (86.562)	Prec@5 100.000 (99.797)
Train: [350/422]	Time 0.031 (0.059)	Loss 0.2703 (0.3615)	Prec@1 92.188 (86.812)	Prec@5 100.000 (99.781)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.4290 (0.3593)	Prec@1 85.938 (86.859)	Prec@5 100.000 (99.734)
Test: [0/47]	Time 0.327 (0.327)	Loss 0.2483 (0.2483)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.033)	Loss 0.3467 (0.3343)	Prec@1 85.938 (88.170)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.021 (0.027)	Loss 0.3484 (0.3563)	Prec@1 90.625 (87.309)	Prec@5 100.000 (99.886)
Test: [6/40] Acc 87.400
epoch: 7
Train: [0/422]	Time 0.376 (0.376)	Loss 0.2704 (0.2704)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.035 (0.064)	Loss 0.4871 (0.3370)	Prec@1 82.812 (87.684)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.063 (0.060)	Loss 0.4366 (0.3430)	Prec@1 87.500 (87.672)	Prec@5 98.438 (99.828)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.3894 (0.3421)	Prec@1 85.938 (87.531)	Prec@5 100.000 (99.812)
Train: [200/422]	Time 0.055 (0.058)	Loss 0.2500 (0.3339)	Prec@1 92.188 (87.328)	Prec@5 100.000 (99.828)
Train: [250/422]	Time 0.062 (0.058)	Loss 0.2781 (0.3318)	Prec@1 87.500 (87.562)	Prec@5 100.000 (99.875)
Train: [300/422]	Time 0.032 (0.059)	Loss 0.3253 (0.3433)	Prec@1 84.375 (87.078)	Prec@5 100.000 (99.891)
Train: [350/422]	Time 0.064 (0.060)	Loss 0.3855 (0.3573)	Prec@1 89.062 (86.516)	Prec@5 100.000 (99.875)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.2169 (0.3521)	Prec@1 90.625 (86.781)	Prec@5 100.000 (99.859)
Test: [0/47]	Time 0.345 (0.345)	Loss 0.2439 (0.2439)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.029)	Loss 0.2896 (0.2937)	Prec@1 87.500 (88.467)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.023 (0.025)	Loss 0.2827 (0.3191)	Prec@1 89.062 (88.148)	Prec@5 100.000 (99.924)
Test: [7/40] Acc 88.233
epoch: 8
Train: [0/422]	Time 0.379 (0.379)	Loss 0.2747 (0.2747)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.049 (0.067)	Loss 0.2419 (0.2899)	Prec@1 90.625 (89.154)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.065 (0.060)	Loss 0.3961 (0.3268)	Prec@1 84.375 (88.141)	Prec@5 100.000 (99.891)
Train: [150/422]	Time 0.069 (0.058)	Loss 0.3347 (0.3486)	Prec@1 87.500 (87.234)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.064 (0.059)	Loss 0.2189 (0.3364)	Prec@1 95.312 (87.328)	Prec@5 100.000 (99.922)
Train: [250/422]	Time 0.062 (0.059)	Loss 0.3194 (0.3327)	Prec@1 89.062 (87.281)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.031 (0.060)	Loss 0.3356 (0.3281)	Prec@1 87.500 (87.344)	Prec@5 100.000 (99.875)
Train: [350/422]	Time 0.065 (0.060)	Loss 0.3637 (0.3295)	Prec@1 85.938 (87.484)	Prec@5 100.000 (99.859)
Train: [400/422]	Time 0.068 (0.059)	Loss 0.3139 (0.3336)	Prec@1 85.938 (87.531)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.346 (0.346)	Loss 0.2326 (0.2326)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.010 (0.032)	Loss 0.3132 (0.2953)	Prec@1 90.625 (88.690)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.025)	Loss 0.2917 (0.3212)	Prec@1 89.062 (88.338)	Prec@5 100.000 (99.924)
Test: [8/40] Acc 88.533
epoch: 9
Train: [0/422]	Time 0.373 (0.373)	Loss 0.2235 (0.2235)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.067)	Loss 0.3807 (0.3196)	Prec@1 85.938 (88.358)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.065 (0.060)	Loss 0.1997 (0.3101)	Prec@1 92.188 (88.531)	Prec@5 100.000 (99.938)
Train: [150/422]	Time 0.069 (0.059)	Loss 0.3638 (0.3201)	Prec@1 82.812 (88.047)	Prec@5 100.000 (99.875)
Train: [200/422]	Time 0.064 (0.059)	Loss 0.4775 (0.3226)	Prec@1 78.125 (87.688)	Prec@5 100.000 (99.797)
Train: [250/422]	Time 0.043 (0.059)	Loss 0.2890 (0.3119)	Prec@1 90.625 (88.047)	Prec@5 100.000 (99.875)
Train: [300/422]	Time 0.063 (0.060)	Loss 0.2018 (0.3197)	Prec@1 90.625 (88.000)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.065 (0.060)	Loss 0.3075 (0.3195)	Prec@1 87.500 (88.219)	Prec@5 100.000 (99.906)
Train: [400/422]	Time 0.070 (0.058)	Loss 0.4313 (0.3259)	Prec@1 84.375 (88.328)	Prec@5 100.000 (99.844)
Test: [0/47]	Time 0.335 (0.335)	Loss 0.2560 (0.2560)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.009 (0.034)	Loss 0.3504 (0.2748)	Prec@1 87.500 (89.881)	Prec@5 100.000 (99.777)
Test: [40/47]	Time 0.022 (0.025)	Loss 0.3190 (0.3010)	Prec@1 89.062 (89.405)	Prec@5 100.000 (99.809)
Test: [9/40] Acc 89.300
epoch: 10
Train: [0/422]	Time 0.369 (0.369)	Loss 0.3333 (0.3333)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.067)	Loss 0.3487 (0.2941)	Prec@1 87.500 (89.246)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.065 (0.060)	Loss 0.3114 (0.3068)	Prec@1 90.625 (88.641)	Prec@5 100.000 (99.906)
Train: [150/422]	Time 0.069 (0.058)	Loss 0.3563 (0.3226)	Prec@1 84.375 (88.062)	Prec@5 100.000 (99.922)
Train: [200/422]	Time 0.063 (0.058)	Loss 0.3709 (0.3091)	Prec@1 89.062 (88.500)	Prec@5 100.000 (99.906)
Train: [250/422]	Time 0.032 (0.059)	Loss 0.4662 (0.2955)	Prec@1 84.375 (88.844)	Prec@5 100.000 (99.891)
Train: [300/422]	Time 0.065 (0.060)	Loss 0.4487 (0.3088)	Prec@1 84.375 (88.562)	Prec@5 100.000 (99.859)
Train: [350/422]	Time 0.069 (0.060)	Loss 0.4325 (0.3221)	Prec@1 82.812 (87.969)	Prec@5 100.000 (99.891)
Train: [400/422]	Time 0.069 (0.059)	Loss 0.3591 (0.3271)	Prec@1 90.625 (87.906)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.368 (0.368)	Loss 0.2334 (0.2334)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.010 (0.035)	Loss 0.3256 (0.2876)	Prec@1 92.188 (89.732)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.021 (0.026)	Loss 0.2537 (0.3059)	Prec@1 92.188 (89.062)	Prec@5 100.000 (99.848)
Test: [10/40] Acc 89.267
epoch: 11
Train: [0/422]	Time 0.407 (0.407)	Loss 0.4985 (0.4985)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.065)	Loss 0.2346 (0.2995)	Prec@1 95.312 (88.511)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.070 (0.059)	Loss 0.3068 (0.2992)	Prec@1 87.500 (88.844)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.062 (0.059)	Loss 0.2677 (0.2973)	Prec@1 90.625 (88.844)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.045 (0.059)	Loss 0.3019 (0.2909)	Prec@1 85.938 (88.844)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.060 (0.060)	Loss 0.3310 (0.2935)	Prec@1 82.812 (88.969)	Prec@5 100.000 (99.953)
Train: [300/422]	Time 0.065 (0.060)	Loss 0.3278 (0.3095)	Prec@1 85.938 (88.547)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.068 (0.059)	Loss 0.3367 (0.3234)	Prec@1 87.500 (87.953)	Prec@5 100.000 (99.906)
Train: [400/422]	Time 0.065 (0.059)	Loss 0.2039 (0.3102)	Prec@1 93.750 (88.422)	Prec@5 100.000 (99.891)
Test: [0/47]	Time 0.328 (0.328)	Loss 0.2215 (0.2215)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.037)	Loss 0.2448 (0.2556)	Prec@1 90.625 (90.699)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.234 (0.031)	Loss 0.2747 (0.2812)	Prec@1 90.625 (89.558)	Prec@5 100.000 (99.924)
Test: [11/40] Acc 89.633
epoch: 12
Train: [0/422]	Time 0.393 (0.393)	Loss 0.3372 (0.3372)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.060 (0.068)	Loss 0.2597 (0.2939)	Prec@1 90.625 (88.940)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.065 (0.060)	Loss 0.2269 (0.2983)	Prec@1 90.625 (89.000)	Prec@5 100.000 (99.922)
Train: [150/422]	Time 0.068 (0.059)	Loss 0.3263 (0.2943)	Prec@1 85.938 (89.172)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.064 (0.058)	Loss 0.2352 (0.2801)	Prec@1 87.500 (89.438)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.060 (0.059)	Loss 0.2735 (0.2853)	Prec@1 92.188 (89.172)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.059 (0.060)	Loss 0.2711 (0.3000)	Prec@1 92.188 (89.000)	Prec@5 100.000 (99.844)
Train: [350/422]	Time 0.065 (0.060)	Loss 0.2021 (0.3060)	Prec@1 93.750 (88.453)	Prec@5 100.000 (99.812)
Train: [400/422]	Time 0.068 (0.059)	Loss 0.2460 (0.2944)	Prec@1 89.062 (88.594)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.338 (0.338)	Loss 0.1718 (0.1718)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.009 (0.030)	Loss 0.2628 (0.2642)	Prec@1 84.375 (89.211)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.025)	Loss 0.2802 (0.2902)	Prec@1 89.062 (89.024)	Prec@5 100.000 (99.886)
Test: [12/40] Acc 89.300
epoch: 13
Train: [0/422]	Time 0.388 (0.388)	Loss 0.4194 (0.4194)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.065)	Loss 0.2042 (0.2816)	Prec@1 90.625 (89.430)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.069 (0.058)	Loss 0.1236 (0.2707)	Prec@1 98.438 (89.766)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.063 (0.059)	Loss 0.2442 (0.2853)	Prec@1 95.312 (89.266)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.032 (0.059)	Loss 0.3219 (0.2903)	Prec@1 87.500 (89.312)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.060 (0.060)	Loss 0.1451 (0.2772)	Prec@1 96.875 (89.766)	Prec@5 100.000 (99.953)
Train: [300/422]	Time 0.065 (0.060)	Loss 0.1976 (0.2794)	Prec@1 93.750 (89.359)	Prec@5 100.000 (99.922)
Train: [350/422]	Time 0.069 (0.059)	Loss 0.3256 (0.2844)	Prec@1 92.188 (89.047)	Prec@5 100.000 (99.891)
Train: [400/422]	Time 0.064 (0.059)	Loss 0.2522 (0.2924)	Prec@1 87.500 (88.875)	Prec@5 100.000 (99.906)
Test: [0/47]	Time 0.340 (0.340)	Loss 0.2035 (0.2035)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.037)	Loss 0.2752 (0.2525)	Prec@1 89.062 (89.881)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.025)	Loss 0.2196 (0.2757)	Prec@1 95.312 (89.710)	Prec@5 100.000 (99.924)
Test: [13/40] Acc 89.700
epoch: 14
Train: [0/422]	Time 0.377 (0.377)	Loss 0.3641 (0.3641)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.065)	Loss 0.3101 (0.2747)	Prec@1 90.625 (89.522)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.068 (0.058)	Loss 0.2987 (0.2800)	Prec@1 90.625 (89.688)	Prec@5 100.000 (99.859)
Train: [150/422]	Time 0.063 (0.058)	Loss 0.4105 (0.2832)	Prec@1 85.938 (89.766)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.030 (0.059)	Loss 0.1562 (0.2723)	Prec@1 92.188 (89.812)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.2017 (0.2732)	Prec@1 90.625 (89.719)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.2693 (0.2765)	Prec@1 89.062 (89.656)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.056 (0.058)	Loss 0.2198 (0.2697)	Prec@1 92.188 (90.031)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.061 (0.059)	Loss 0.2599 (0.2796)	Prec@1 87.500 (89.609)	Prec@5 100.000 (99.938)
Test: [0/47]	Time 0.310 (0.310)	Loss 0.1932 (0.1932)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.036)	Loss 0.1970 (0.2714)	Prec@1 93.750 (90.179)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.010 (0.027)	Loss 0.2539 (0.2927)	Prec@1 93.750 (89.444)	Prec@5 100.000 (99.962)
Test: [14/40] Acc 89.567
epoch: 15
Train: [0/422]	Time 0.397 (0.397)	Loss 0.2179 (0.2179)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.066)	Loss 0.2605 (0.2655)	Prec@1 92.188 (90.012)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.060 (0.059)	Loss 0.1540 (0.2680)	Prec@1 90.625 (90.016)	Prec@5 100.000 (99.875)
Train: [150/422]	Time 0.039 (0.059)	Loss 0.2810 (0.2689)	Prec@1 87.500 (90.000)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.4001 (0.2633)	Prec@1 79.688 (90.141)	Prec@5 100.000 (99.891)
Train: [250/422]	Time 0.066 (0.060)	Loss 0.2682 (0.2702)	Prec@1 90.625 (90.078)	Prec@5 100.000 (99.891)
Train: [300/422]	Time 0.068 (0.058)	Loss 0.2638 (0.2649)	Prec@1 90.625 (90.203)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.064 (0.059)	Loss 0.1564 (0.2498)	Prec@1 90.625 (90.438)	Prec@5 100.000 (99.969)
Train: [400/422]	Time 0.045 (0.059)	Loss 0.2254 (0.2543)	Prec@1 90.625 (90.391)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.328 (0.328)	Loss 0.2070 (0.2070)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Test: [20/47]	Time 0.023 (0.037)	Loss 0.2819 (0.2733)	Prec@1 90.625 (89.360)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.008 (0.029)	Loss 0.2429 (0.2931)	Prec@1 92.188 (89.139)	Prec@5 100.000 (99.886)
Test: [15/40] Acc 89.200
epoch: 16
Train: [0/422]	Time 0.411 (0.411)	Loss 0.1418 (0.1418)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.066)	Loss 0.3713 (0.2518)	Prec@1 82.812 (89.859)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.061 (0.059)	Loss 0.4170 (0.2591)	Prec@1 82.812 (89.766)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.054 (0.060)	Loss 0.2913 (0.2642)	Prec@1 85.938 (89.750)	Prec@5 100.000 (99.938)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.3630 (0.2586)	Prec@1 85.938 (90.219)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.068 (0.059)	Loss 0.2479 (0.2554)	Prec@1 90.625 (90.453)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.060 (0.059)	Loss 0.2113 (0.2647)	Prec@1 87.500 (90.125)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.2176 (0.2658)	Prec@1 93.750 (90.172)	Prec@5 100.000 (99.906)
Train: [400/422]	Time 0.031 (0.060)	Loss 0.2298 (0.2606)	Prec@1 89.062 (90.016)	Prec@5 100.000 (99.938)
Test: [0/47]	Time 0.330 (0.330)	Loss 0.2156 (0.2156)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.035)	Loss 0.2099 (0.2453)	Prec@1 93.750 (90.327)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.022 (0.029)	Loss 0.2490 (0.2698)	Prec@1 92.188 (89.748)	Prec@5 100.000 (99.962)
Test: [16/40] Acc 89.733
epoch: 17
Train: [0/422]	Time 0.390 (0.390)	Loss 0.2709 (0.2709)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.035 (0.064)	Loss 0.3011 (0.2603)	Prec@1 85.938 (90.656)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.060 (0.058)	Loss 0.2546 (0.2556)	Prec@1 87.500 (90.281)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.028 (0.059)	Loss 0.2161 (0.2531)	Prec@1 89.062 (90.109)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.028 (0.044)	Loss 0.2586 (0.2503)	Prec@1 90.625 (90.516)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.069 (0.041)	Loss 0.2703 (0.2619)	Prec@1 92.188 (90.141)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.065 (0.057)	Loss 0.1657 (0.2589)	Prec@1 95.312 (90.297)	Prec@5 100.000 (99.984)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.2443 (0.2475)	Prec@1 89.062 (90.484)	Prec@5 100.000 (99.938)
Train: [400/422]	Time 0.031 (0.060)	Loss 0.2275 (0.2597)	Prec@1 92.188 (89.984)	Prec@5 100.000 (99.938)
Test: [0/47]	Time 0.334 (0.334)	Loss 0.1756 (0.1756)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.036)	Loss 0.2888 (0.2491)	Prec@1 92.188 (91.071)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.022 (0.029)	Loss 0.2096 (0.2596)	Prec@1 93.750 (90.625)	Prec@5 100.000 (99.924)
Test: [17/40] Acc 90.633
epoch: 18
Train: [0/422]	Time 0.383 (0.383)	Loss 0.1434 (0.1434)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.056 (0.064)	Loss 0.2678 (0.2487)	Prec@1 89.062 (90.502)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.060 (0.058)	Loss 0.1412 (0.2419)	Prec@1 95.312 (91.000)	Prec@5 100.000 (99.938)
Train: [150/422]	Time 0.030 (0.060)	Loss 0.2726 (0.2369)	Prec@1 87.500 (91.266)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.065 (0.059)	Loss 0.2431 (0.2483)	Prec@1 90.625 (90.594)	Prec@5 100.000 (99.969)
Train: [250/422]	Time 0.073 (0.058)	Loss 0.2213 (0.2401)	Prec@1 90.625 (90.844)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.064 (0.058)	Loss 0.2058 (0.2404)	Prec@1 95.312 (90.547)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.3164 (0.2555)	Prec@1 89.062 (90.172)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.060 (0.060)	Loss 0.1338 (0.2567)	Prec@1 93.750 (90.641)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.332 (0.332)	Loss 0.2008 (0.2008)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.035)	Loss 0.3838 (0.2672)	Prec@1 85.938 (90.030)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.021 (0.028)	Loss 0.2106 (0.2835)	Prec@1 92.188 (89.748)	Prec@5 100.000 (99.848)
Test: [18/40] Acc 89.900
epoch: 19
Train: [0/422]	Time 0.371 (0.371)	Loss 0.1812 (0.1812)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.042 (0.065)	Loss 0.2540 (0.2284)	Prec@1 89.062 (91.912)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.063 (0.060)	Loss 0.2187 (0.2310)	Prec@1 93.750 (91.484)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.2603 (0.2445)	Prec@1 92.188 (90.594)	Prec@5 98.438 (99.984)
Train: [200/422]	Time 0.069 (0.058)	Loss 0.2540 (0.2465)	Prec@1 85.938 (90.391)	Prec@5 100.000 (99.969)
Train: [250/422]	Time 0.064 (0.058)	Loss 0.1817 (0.2261)	Prec@1 90.625 (91.312)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.048 (0.059)	Loss 0.3017 (0.2364)	Prec@1 84.375 (91.266)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.063 (0.060)	Loss 0.1707 (0.2552)	Prec@1 93.750 (90.438)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.2238 (0.2540)	Prec@1 90.625 (90.500)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.334 (0.334)	Loss 0.2079 (0.2079)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.019 (0.029)	Loss 0.3523 (0.2618)	Prec@1 85.938 (90.030)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.010 (0.024)	Loss 0.2125 (0.2750)	Prec@1 93.750 (89.825)	Prec@5 100.000 (99.886)
Test: [19/40] Acc 89.900
epoch: 20
Train: [0/422]	Time 0.358 (0.358)	Loss 0.1462 (0.1462)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.064)	Loss 0.1914 (0.2187)	Prec@1 92.188 (91.759)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.068 (0.059)	Loss 0.3291 (0.2305)	Prec@1 85.938 (91.297)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.064 (0.059)	Loss 0.1057 (0.2341)	Prec@1 95.312 (91.234)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.063 (0.059)	Loss 0.1966 (0.2390)	Prec@1 92.188 (91.109)	Prec@5 100.000 (99.922)
Train: [250/422]	Time 0.044 (0.060)	Loss 0.2161 (0.2405)	Prec@1 90.625 (90.781)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.068 (0.060)	Loss 0.2092 (0.2226)	Prec@1 92.188 (91.328)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.069 (0.059)	Loss 0.4009 (0.2280)	Prec@1 82.812 (91.375)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.064 (0.058)	Loss 0.2486 (0.2371)	Prec@1 92.188 (91.312)	Prec@5 100.000 (99.953)
Test: [0/47]	Time 0.348 (0.348)	Loss 0.1506 (0.1506)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.037)	Loss 0.3510 (0.2723)	Prec@1 87.500 (90.179)	Prec@5 98.438 (99.926)
Test: [40/47]	Time 0.021 (0.026)	Loss 0.2502 (0.2862)	Prec@1 89.062 (89.901)	Prec@5 100.000 (99.924)
Test: [20/40] Acc 90.033
epoch: 21
Train: [0/422]	Time 0.370 (0.370)	Loss 0.3109 (0.3109)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.065)	Loss 0.2248 (0.2534)	Prec@1 87.500 (89.920)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.064 (0.059)	Loss 0.3354 (0.2459)	Prec@1 87.500 (90.406)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.062 (0.059)	Loss 0.1420 (0.2359)	Prec@1 96.875 (91.234)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.049 (0.060)	Loss 0.2090 (0.2199)	Prec@1 90.625 (91.828)	Prec@5 100.000 (99.969)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.1631 (0.2163)	Prec@1 93.750 (91.906)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.2587 (0.2278)	Prec@1 90.625 (91.312)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.063 (0.059)	Loss 0.2125 (0.2263)	Prec@1 92.188 (91.250)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.064 (0.059)	Loss 0.1544 (0.2328)	Prec@1 96.875 (91.172)	Prec@5 100.000 (99.969)
Test: [0/47]	Time 0.342 (0.342)	Loss 0.1530 (0.1530)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.038)	Loss 0.3064 (0.2481)	Prec@1 87.500 (90.551)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.009 (0.028)	Loss 0.1913 (0.2598)	Prec@1 96.875 (90.816)	Prec@5 100.000 (99.924)
Test: [21/40] Acc 90.933
epoch: 22
Train: [0/422]	Time 0.393 (0.393)	Loss 0.2370 (0.2370)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.068 (0.065)	Loss 0.1588 (0.2121)	Prec@1 93.750 (92.310)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.049 (0.058)	Loss 0.5010 (0.2101)	Prec@1 81.250 (92.328)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.062 (0.059)	Loss 0.1957 (0.2138)	Prec@1 90.625 (92.125)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.033 (0.059)	Loss 0.2606 (0.2234)	Prec@1 84.375 (91.859)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.4915 (0.2276)	Prec@1 87.500 (91.812)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.2066 (0.2234)	Prec@1 90.625 (91.812)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.036 (0.058)	Loss 0.3093 (0.2357)	Prec@1 87.500 (91.141)	Prec@5 100.000 (99.969)
Train: [400/422]	Time 0.060 (0.059)	Loss 0.3788 (0.2402)	Prec@1 87.500 (90.844)	Prec@5 100.000 (99.969)
Test: [0/47]	Time 0.355 (0.355)	Loss 0.1673 (0.1673)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.037)	Loss 0.3285 (0.2532)	Prec@1 87.500 (90.179)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.009 (0.026)	Loss 0.2371 (0.2739)	Prec@1 90.625 (90.091)	Prec@5 100.000 (99.924)
Test: [22/40] Acc 90.333
epoch: 23
Train: [0/422]	Time 0.394 (0.394)	Loss 0.3321 (0.3321)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.1361 (0.2200)	Prec@1 95.312 (91.544)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.2803 (0.2143)	Prec@1 90.625 (91.844)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.031 (0.060)	Loss 0.1153 (0.2192)	Prec@1 96.875 (91.766)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.2494 (0.2198)	Prec@1 87.500 (91.578)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.069 (0.059)	Loss 0.2550 (0.2286)	Prec@1 90.625 (91.219)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.035 (0.058)	Loss 0.2522 (0.2346)	Prec@1 89.062 (91.016)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.062 (0.059)	Loss 0.1152 (0.2253)	Prec@1 96.875 (91.422)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.032 (0.060)	Loss 0.2831 (0.2219)	Prec@1 90.625 (91.656)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.345 (0.345)	Loss 0.1685 (0.1685)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.037)	Loss 0.2267 (0.2409)	Prec@1 92.188 (91.592)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.020 (0.029)	Loss 0.2685 (0.2593)	Prec@1 92.188 (91.197)	Prec@5 100.000 (99.886)
Test: [23/40] Acc 91.267
epoch: 24
Train: [0/422]	Time 0.384 (0.384)	Loss 0.2230 (0.2230)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.066)	Loss 0.3543 (0.2115)	Prec@1 92.188 (91.728)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.064 (0.059)	Loss 0.2140 (0.2161)	Prec@1 93.750 (91.875)	Prec@5 100.000 (99.969)
Train: [150/422]	Time 0.031 (0.059)	Loss 0.1947 (0.2169)	Prec@1 92.188 (91.969)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.062 (0.060)	Loss 0.2698 (0.2097)	Prec@1 89.062 (92.219)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.3316 (0.2111)	Prec@1 87.500 (92.156)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.069 (0.058)	Loss 0.1346 (0.2109)	Prec@1 92.188 (91.766)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.063 (0.058)	Loss 0.1076 (0.2114)	Prec@1 96.875 (91.953)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.038 (0.059)	Loss 0.2625 (0.2198)	Prec@1 92.188 (92.062)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.320 (0.320)	Loss 0.1601 (0.1601)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.034)	Loss 0.2699 (0.2604)	Prec@1 89.062 (90.402)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.020 (0.028)	Loss 0.2742 (0.2732)	Prec@1 90.625 (90.206)	Prec@5 100.000 (99.886)
Test: [24/40] Acc 90.367
epoch: 25
Train: [0/422]	Time 0.367 (0.367)	Loss 0.2168 (0.2168)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.062 (0.065)	Loss 0.1764 (0.2173)	Prec@1 93.750 (91.759)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.032 (0.059)	Loss 0.2433 (0.2157)	Prec@1 89.062 (92.062)	Prec@5 100.000 (99.969)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.1124 (0.2138)	Prec@1 95.312 (92.125)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.069 (0.059)	Loss 0.2088 (0.2080)	Prec@1 90.625 (92.141)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.044 (0.058)	Loss 0.1290 (0.2060)	Prec@1 93.750 (91.891)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.062 (0.058)	Loss 0.2178 (0.2011)	Prec@1 93.750 (91.984)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.035 (0.059)	Loss 0.1961 (0.1978)	Prec@1 89.062 (92.422)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.1276 (0.2107)	Prec@1 95.312 (91.672)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.322 (0.322)	Loss 0.1590 (0.1590)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.034)	Loss 0.2325 (0.2350)	Prec@1 87.500 (91.369)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.023 (0.028)	Loss 0.2829 (0.2591)	Prec@1 92.188 (90.854)	Prec@5 100.000 (99.962)
Test: [25/40] Acc 91.067
epoch: 26
Train: [0/422]	Time 0.395 (0.395)	Loss 0.1021 (0.1021)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.034 (0.066)	Loss 0.1861 (0.1907)	Prec@1 89.062 (92.494)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.062 (0.060)	Loss 0.2874 (0.2031)	Prec@1 85.938 (92.359)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.2257 (0.2124)	Prec@1 93.750 (92.266)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.069 (0.059)	Loss 0.1510 (0.2069)	Prec@1 95.312 (92.516)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.064 (0.058)	Loss 0.1034 (0.2034)	Prec@1 96.875 (92.453)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.030 (0.059)	Loss 0.2652 (0.2125)	Prec@1 90.625 (92.078)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.063 (0.060)	Loss 0.3055 (0.2169)	Prec@1 87.500 (92.062)	Prec@5 100.000 (99.969)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.1348 (0.2090)	Prec@1 96.875 (92.281)	Prec@5 100.000 (99.938)
Test: [0/47]	Time 0.348 (0.348)	Loss 0.1550 (0.1550)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.030)	Loss 0.2226 (0.2523)	Prec@1 90.625 (90.774)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.009 (0.026)	Loss 0.3164 (0.2806)	Prec@1 89.062 (90.091)	Prec@5 100.000 (99.962)
Test: [26/40] Acc 90.500
epoch: 27
Train: [0/422]	Time 0.359 (0.359)	Loss 0.1896 (0.1896)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.066)	Loss 0.1501 (0.1839)	Prec@1 96.875 (93.045)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.068 (0.059)	Loss 0.2279 (0.1963)	Prec@1 90.625 (92.781)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.065 (0.058)	Loss 0.2242 (0.1997)	Prec@1 89.062 (92.422)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.060 (0.059)	Loss 0.1700 (0.1972)	Prec@1 93.750 (92.297)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.037 (0.060)	Loss 0.1169 (0.2012)	Prec@1 96.875 (92.156)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.065 (0.061)	Loss 0.1536 (0.1934)	Prec@1 95.312 (92.312)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.069 (0.059)	Loss 0.1817 (0.1973)	Prec@1 92.188 (92.391)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.069 (0.059)	Loss 0.3074 (0.2123)	Prec@1 90.625 (91.953)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.349 (0.349)	Loss 0.1636 (0.1636)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.009 (0.034)	Loss 0.2459 (0.2470)	Prec@1 89.062 (91.964)	Prec@5 98.438 (99.926)
Test: [40/47]	Time 0.021 (0.026)	Loss 0.2638 (0.2708)	Prec@1 89.062 (90.777)	Prec@5 100.000 (99.924)
Test: [27/40] Acc 91.067
epoch: 28
Train: [0/422]	Time 0.404 (0.404)	Loss 0.2184 (0.2184)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.065)	Loss 0.1107 (0.1805)	Prec@1 95.312 (93.719)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.069 (0.058)	Loss 0.1329 (0.1896)	Prec@1 95.312 (92.891)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.064 (0.059)	Loss 0.2459 (0.2050)	Prec@1 90.625 (91.891)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.028 (0.050)	Loss 0.2970 (0.1985)	Prec@1 89.062 (92.500)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.059 (0.043)	Loss 0.0889 (0.1912)	Prec@1 96.875 (93.047)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.065 (0.052)	Loss 0.2100 (0.1890)	Prec@1 92.188 (93.141)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.068 (0.059)	Loss 0.2766 (0.1951)	Prec@1 92.188 (92.781)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.063 (0.059)	Loss 0.1950 (0.2027)	Prec@1 93.750 (92.328)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.353 (0.353)	Loss 0.1410 (0.1410)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.039)	Loss 0.2793 (0.2543)	Prec@1 89.062 (90.774)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.023 (0.028)	Loss 0.2921 (0.2856)	Prec@1 89.062 (90.091)	Prec@5 100.000 (99.962)
Test: [28/40] Acc 90.267
epoch: 29
Train: [0/422]	Time 0.387 (0.387)	Loss 0.2442 (0.2442)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.064)	Loss 0.2451 (0.1773)	Prec@1 93.750 (93.719)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.064 (0.059)	Loss 0.1131 (0.1697)	Prec@1 95.312 (93.750)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.067 (0.059)	Loss 0.1601 (0.1795)	Prec@1 98.438 (93.375)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.031 (0.060)	Loss 0.3134 (0.2001)	Prec@1 87.500 (92.562)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.1276 (0.1969)	Prec@1 95.312 (92.328)	Prec@5 100.000 (99.969)
Train: [300/422]	Time 0.068 (0.059)	Loss 0.2665 (0.1840)	Prec@1 89.062 (93.156)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.064 (0.058)	Loss 0.2760 (0.1966)	Prec@1 89.062 (92.891)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.062 (0.059)	Loss 0.1058 (0.2019)	Prec@1 96.875 (92.297)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.344 (0.344)	Loss 0.2029 (0.2029)	Prec@1 93.750 (93.750)	Prec@5 98.438 (98.438)
Test: [20/47]	Time 0.022 (0.038)	Loss 0.3805 (0.2489)	Prec@1 82.812 (90.997)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.010 (0.027)	Loss 0.2215 (0.2741)	Prec@1 90.625 (90.625)	Prec@5 100.000 (99.924)
Test: [29/40] Acc 90.833
epoch: 30
Train: [0/422]	Time 0.413 (0.413)	Loss 0.1965 (0.1965)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.042 (0.065)	Loss 0.2377 (0.1885)	Prec@1 89.062 (93.137)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.2564 (0.1900)	Prec@1 89.062 (92.969)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.031 (0.060)	Loss 0.2483 (0.1902)	Prec@1 90.625 (92.984)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.064 (0.061)	Loss 0.1224 (0.1792)	Prec@1 93.750 (93.406)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.065 (0.060)	Loss 0.2284 (0.1811)	Prec@1 92.188 (93.000)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.1573 (0.1889)	Prec@1 93.750 (92.656)	Prec@5 100.000 (99.984)
Train: [350/422]	Time 0.064 (0.059)	Loss 0.2009 (0.1870)	Prec@1 92.188 (92.875)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.059 (0.059)	Loss 0.2750 (0.1896)	Prec@1 90.625 (92.859)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.329 (0.329)	Loss 0.1673 (0.1673)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Test: [20/47]	Time 0.025 (0.037)	Loss 0.3348 (0.2430)	Prec@1 89.062 (90.923)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.009 (0.029)	Loss 0.2367 (0.2732)	Prec@1 92.188 (90.701)	Prec@5 100.000 (99.924)
Test: [30/40] Acc 91.033
epoch: 31
Train: [0/422]	Time 0.409 (0.409)	Loss 0.1331 (0.1331)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.2119 (0.1736)	Prec@1 89.062 (93.076)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.1364 (0.1804)	Prec@1 95.312 (93.031)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.033 (0.060)	Loss 0.2001 (0.1756)	Prec@1 90.625 (93.484)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.1558 (0.1735)	Prec@1 96.875 (93.203)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.068 (0.060)	Loss 0.1492 (0.1806)	Prec@1 92.188 (92.594)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.066 (0.059)	Loss 0.1557 (0.1811)	Prec@1 93.750 (92.953)	Prec@5 100.000 (99.984)
Train: [350/422]	Time 0.063 (0.059)	Loss 0.1526 (0.1807)	Prec@1 95.312 (93.219)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.032 (0.059)	Loss 0.1606 (0.1822)	Prec@1 92.188 (93.109)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.347 (0.347)	Loss 0.1962 (0.1962)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.037)	Loss 0.4209 (0.2797)	Prec@1 87.500 (90.997)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.012 (0.030)	Loss 0.2412 (0.2928)	Prec@1 93.750 (90.473)	Prec@5 100.000 (99.924)
Test: [31/40] Acc 90.767
epoch: 32
Train: [0/422]	Time 0.396 (0.396)	Loss 0.1998 (0.1998)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.066)	Loss 0.0753 (0.1697)	Prec@1 98.438 (93.873)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.1257 (0.1701)	Prec@1 95.312 (93.703)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.040 (0.060)	Loss 0.0529 (0.1747)	Prec@1 100.000 (93.375)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.067 (0.060)	Loss 0.2070 (0.1762)	Prec@1 92.188 (93.312)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.069 (0.059)	Loss 0.2629 (0.1790)	Prec@1 89.062 (93.438)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.050 (0.059)	Loss 0.0767 (0.1788)	Prec@1 98.438 (93.344)	Prec@5 100.000 (99.984)
Train: [350/422]	Time 0.063 (0.060)	Loss 0.3459 (0.1787)	Prec@1 89.062 (93.156)	Prec@5 100.000 (99.969)
Train: [400/422]	Time 0.029 (0.059)	Loss 0.2574 (0.1861)	Prec@1 89.062 (93.047)	Prec@5 100.000 (99.984)
Test: [0/47]	Time 0.320 (0.320)	Loss 0.0964 (0.0964)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.022 (0.035)	Loss 0.3709 (0.2454)	Prec@1 89.062 (91.443)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.020 (0.028)	Loss 0.2056 (0.2695)	Prec@1 93.750 (91.044)	Prec@5 100.000 (99.886)
Test: [32/40] Acc 91.233
epoch: 33
Train: [0/422]	Time 0.342 (0.342)	Loss 0.1256 (0.1256)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.061 (0.065)	Loss 0.1756 (0.1689)	Prec@1 90.625 (93.781)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.031 (0.060)	Loss 0.1587 (0.1744)	Prec@1 90.625 (93.547)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.1993 (0.1815)	Prec@1 90.625 (93.250)	Prec@5 100.000 (99.984)
Train: [200/422]	Time 0.069 (0.059)	Loss 0.1009 (0.1797)	Prec@1 95.312 (93.297)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.037 (0.058)	Loss 0.2794 (0.1756)	Prec@1 90.625 (93.422)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.062 (0.059)	Loss 0.1604 (0.1766)	Prec@1 95.312 (93.344)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.032 (0.060)	Loss 0.2460 (0.1722)	Prec@1 89.062 (93.516)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.064 (0.060)	Loss 0.3032 (0.1740)	Prec@1 92.188 (93.703)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.329 (0.329)	Loss 0.1369 (0.1369)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.015 (0.036)	Loss 0.3526 (0.2453)	Prec@1 84.375 (91.369)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.020 (0.028)	Loss 0.2270 (0.2601)	Prec@1 93.750 (90.854)	Prec@5 100.000 (99.886)
Test: [33/40] Acc 90.933
epoch: 34
Train: [0/422]	Time 0.391 (0.391)	Loss 0.2612 (0.2612)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.038 (0.065)	Loss 0.0861 (0.1646)	Prec@1 98.438 (93.505)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.060 (0.060)	Loss 0.0480 (0.1600)	Prec@1 100.000 (93.844)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.065 (0.060)	Loss 0.0793 (0.1596)	Prec@1 96.875 (94.031)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.069 (0.059)	Loss 0.1240 (0.1742)	Prec@1 95.312 (93.500)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.064 (0.059)	Loss 0.1466 (0.1745)	Prec@1 92.188 (93.609)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.062 (0.059)	Loss 0.1781 (0.1613)	Prec@1 90.625 (94.250)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.056 (0.060)	Loss 0.1662 (0.1686)	Prec@1 93.750 (93.422)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.065 (0.060)	Loss 0.2644 (0.1656)	Prec@1 87.500 (93.500)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.319 (0.319)	Loss 0.1963 (0.1963)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.028)	Loss 0.2682 (0.2561)	Prec@1 89.062 (91.220)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.021 (0.024)	Loss 0.2412 (0.2767)	Prec@1 92.188 (90.930)	Prec@5 100.000 (99.962)
Test: [34/40] Acc 91.233
epoch: 35
Train: [0/422]	Time 0.347 (0.347)	Loss 0.0809 (0.0809)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.065 (0.065)	Loss 0.1922 (0.1559)	Prec@1 92.188 (94.271)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.068 (0.059)	Loss 0.0739 (0.1556)	Prec@1 98.438 (94.031)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.062 (0.059)	Loss 0.1722 (0.1483)	Prec@1 93.750 (94.266)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.062 (0.059)	Loss 0.1099 (0.1509)	Prec@1 96.875 (94.281)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.044 (0.060)	Loss 0.0928 (0.1637)	Prec@1 96.875 (93.641)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.065 (0.060)	Loss 0.1762 (0.1694)	Prec@1 93.750 (93.797)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.069 (0.059)	Loss 0.1248 (0.1724)	Prec@1 95.312 (93.844)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.064 (0.058)	Loss 0.1180 (0.1754)	Prec@1 95.312 (93.531)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.310 (0.310)	Loss 0.1596 (0.1596)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.020 (0.036)	Loss 0.3006 (0.2489)	Prec@1 87.500 (90.848)	Prec@5 98.438 (99.926)
Test: [40/47]	Time 0.008 (0.025)	Loss 0.2018 (0.2679)	Prec@1 92.188 (91.006)	Prec@5 100.000 (99.924)
Test: [35/40] Acc 91.133
epoch: 36
Train: [0/422]	Time 0.408 (0.408)	Loss 0.0712 (0.0712)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.066 (0.065)	Loss 0.1061 (0.1463)	Prec@1 96.875 (94.516)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.065 (0.059)	Loss 0.1688 (0.1455)	Prec@1 93.750 (94.531)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.062 (0.060)	Loss 0.1620 (0.1521)	Prec@1 96.875 (94.203)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.039 (0.060)	Loss 0.1972 (0.1563)	Prec@1 93.750 (93.766)	Prec@5 100.000 (99.969)
Train: [250/422]	Time 0.068 (0.060)	Loss 0.1370 (0.1538)	Prec@1 93.750 (94.000)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.069 (0.059)	Loss 0.1874 (0.1603)	Prec@1 90.625 (93.875)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.064 (0.059)	Loss 0.0909 (0.1694)	Prec@1 98.438 (93.375)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.064 (0.059)	Loss 0.2006 (0.1719)	Prec@1 93.750 (93.406)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.338 (0.338)	Loss 0.1485 (0.1485)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.038)	Loss 0.3154 (0.2698)	Prec@1 85.938 (90.848)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.009 (0.028)	Loss 0.2288 (0.2884)	Prec@1 93.750 (90.739)	Prec@5 100.000 (99.848)
Test: [36/40] Acc 91.133
epoch: 37
Train: [0/422]	Time 0.379 (0.379)	Loss 0.1184 (0.1184)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.1950 (0.1317)	Prec@1 93.750 (95.190)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.060 (0.059)	Loss 0.0898 (0.1348)	Prec@1 98.438 (95.000)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.029 (0.060)	Loss 0.1635 (0.1467)	Prec@1 92.188 (94.547)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.1277 (0.1612)	Prec@1 95.312 (94.016)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.069 (0.059)	Loss 0.0746 (0.1643)	Prec@1 98.438 (93.922)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.064 (0.059)	Loss 0.3140 (0.1625)	Prec@1 82.812 (93.750)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.064 (0.060)	Loss 0.1739 (0.1655)	Prec@1 92.188 (93.484)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.045 (0.060)	Loss 0.1288 (0.1648)	Prec@1 92.188 (93.812)	Prec@5 100.000 (99.969)
Test: [0/47]	Time 0.345 (0.345)	Loss 0.1417 (0.1417)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.037)	Loss 0.3096 (0.2704)	Prec@1 87.500 (90.848)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.017 (0.029)	Loss 0.1848 (0.2824)	Prec@1 93.750 (90.587)	Prec@5 100.000 (99.886)
Test: [37/40] Acc 90.933
epoch: 38
Train: [0/422]	Time 0.378 (0.378)	Loss 0.1000 (0.1000)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.065)	Loss 0.2415 (0.1451)	Prec@1 92.188 (94.424)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.059 (0.059)	Loss 0.1009 (0.1523)	Prec@1 96.875 (94.359)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.049 (0.060)	Loss 0.1193 (0.1593)	Prec@1 95.312 (94.203)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.065 (0.060)	Loss 0.0618 (0.1482)	Prec@1 98.438 (94.438)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.069 (0.058)	Loss 0.2610 (0.1421)	Prec@1 89.062 (94.750)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.063 (0.058)	Loss 0.2035 (0.1637)	Prec@1 93.750 (93.859)	Prec@5 100.000 (99.984)
Train: [350/422]	Time 0.063 (0.059)	Loss 0.1934 (0.1635)	Prec@1 95.312 (94.000)	Prec@5 100.000 (99.984)
Train: [400/422]	Time 0.055 (0.060)	Loss 0.1113 (0.1532)	Prec@1 95.312 (94.344)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.332 (0.332)	Loss 0.1406 (0.1406)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.021 (0.035)	Loss 0.3580 (0.2544)	Prec@1 87.500 (91.146)	Prec@5 98.438 (99.851)
Test: [40/47]	Time 0.022 (0.029)	Loss 0.2369 (0.2738)	Prec@1 90.625 (91.387)	Prec@5 100.000 (99.886)
Test: [38/40] Acc 91.667
epoch: 39
Train: [0/422]	Time 0.388 (0.388)	Loss 0.1903 (0.1903)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.047 (0.065)	Loss 0.0748 (0.1506)	Prec@1 100.000 (93.995)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.062 (0.059)	Loss 0.2250 (0.1472)	Prec@1 90.625 (94.359)	Prec@5 100.000 (99.984)
Train: [150/422]	Time 0.031 (0.059)	Loss 0.1962 (0.1549)	Prec@1 92.188 (94.047)	Prec@5 100.000 (99.984)
Train: [200/422]	Time 0.028 (0.045)	Loss 0.2035 (0.1559)	Prec@1 93.750 (93.828)	Prec@5 100.000 (100.000)
Train: [250/422]	Time 0.062 (0.041)	Loss 0.2184 (0.1466)	Prec@1 90.625 (94.172)	Prec@5 100.000 (100.000)
Train: [300/422]	Time 0.062 (0.056)	Loss 0.1170 (0.1463)	Prec@1 95.312 (94.312)	Prec@5 100.000 (100.000)
Train: [350/422]	Time 0.031 (0.059)	Loss 0.2046 (0.1470)	Prec@1 92.188 (94.266)	Prec@5 100.000 (100.000)
Train: [400/422]	Time 0.064 (0.060)	Loss 0.0901 (0.1516)	Prec@1 96.875 (94.109)	Prec@5 100.000 (100.000)
Test: [0/47]	Time 0.324 (0.324)	Loss 0.1964 (0.1964)	Prec@1 96.875 (96.875)	Prec@5 98.438 (98.438)
Test: [20/47]	Time 0.019 (0.034)	Loss 0.3725 (0.2757)	Prec@1 85.938 (90.625)	Prec@5 98.438 (99.777)
Test: [40/47]	Time 0.022 (0.027)	Loss 0.1675 (0.2959)	Prec@1 92.188 (90.816)	Prec@5 100.000 (99.848)
Test: [39/40] Acc 91.000
best ACC: 91.66666666666667
