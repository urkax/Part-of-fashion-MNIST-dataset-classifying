split train val random seed:8245
RANDOM SEED: 8245
data catagory: train
len of img: 27000
data catagory: val
len of img: 3000
data catagory: test
len of img: 5000
using device: cuda
~fc: Conv2d1.conv.weight
~fc: Conv2d1.bn.weight
~fc: Conv2d1.bn.bias
~fc: Conv2d2.conv.weight
~fc: Conv2d2.bn.weight
~fc: Conv2d2.bn.bias
~fc: Mixed_3a.branch1x1.conv.weight
~fc: Mixed_3a.branch1x1.bn.weight
~fc: Mixed_3a.branch1x1.bn.bias
~fc: Mixed_3a.branch3x3_1.conv.weight
~fc: Mixed_3a.branch3x3_1.bn.weight
~fc: Mixed_3a.branch3x3_1.bn.bias
~fc: Mixed_3a.branch3x3_2.conv.weight
~fc: Mixed_3a.branch3x3_2.bn.weight
~fc: Mixed_3a.branch3x3_2.bn.bias
~fc: Mixed_3a.branch5x5_1.conv.weight
~fc: Mixed_3a.branch5x5_1.bn.weight
~fc: Mixed_3a.branch5x5_1.bn.bias
~fc: Mixed_3a.branch5x5_2.conv.weight
~fc: Mixed_3a.branch5x5_2.bn.weight
~fc: Mixed_3a.branch5x5_2.bn.bias
~fc: Mixed_3a.branch_pool.conv.weight
~fc: Mixed_3a.branch_pool.bn.weight
~fc: Mixed_3a.branch_pool.bn.bias
~fc: Mixed_3b.branch1x1.conv.weight
~fc: Mixed_3b.branch1x1.bn.weight
~fc: Mixed_3b.branch1x1.bn.bias
~fc: Mixed_3b.branch3x3_1.conv.weight
~fc: Mixed_3b.branch3x3_1.bn.weight
~fc: Mixed_3b.branch3x3_1.bn.bias
~fc: Mixed_3b.branch3x3_2.conv.weight
~fc: Mixed_3b.branch3x3_2.bn.weight
~fc: Mixed_3b.branch3x3_2.bn.bias
~fc: Mixed_3b.branch5x5_1.conv.weight
~fc: Mixed_3b.branch5x5_1.bn.weight
~fc: Mixed_3b.branch5x5_1.bn.bias
~fc: Mixed_3b.branch5x5_2.conv.weight
~fc: Mixed_3b.branch5x5_2.bn.weight
~fc: Mixed_3b.branch5x5_2.bn.bias
~fc: Mixed_3b.branch_pool.conv.weight
~fc: Mixed_3b.branch_pool.bn.weight
~fc: Mixed_3b.branch_pool.bn.bias
~fc: Mixed_4a.branch1x1.conv.weight
~fc: Mixed_4a.branch1x1.bn.weight
~fc: Mixed_4a.branch1x1.bn.bias
~fc: Mixed_4a.branch3x3_1.conv.weight
~fc: Mixed_4a.branch3x3_1.bn.weight
~fc: Mixed_4a.branch3x3_1.bn.bias
~fc: Mixed_4a.branch3x3_2.conv.weight
~fc: Mixed_4a.branch3x3_2.bn.weight
~fc: Mixed_4a.branch3x3_2.bn.bias
~fc: Mixed_4a.branch5x5_1.conv.weight
~fc: Mixed_4a.branch5x5_1.bn.weight
~fc: Mixed_4a.branch5x5_1.bn.bias
~fc: Mixed_4a.branch5x5_2.conv.weight
~fc: Mixed_4a.branch5x5_2.bn.weight
~fc: Mixed_4a.branch5x5_2.bn.bias
~fc: Mixed_4a.branch_pool.conv.weight
~fc: Mixed_4a.branch_pool.bn.weight
~fc: Mixed_4a.branch_pool.bn.bias
~fc: Mixed_4b.branch1x1.conv.weight
~fc: Mixed_4b.branch1x1.bn.weight
~fc: Mixed_4b.branch1x1.bn.bias
~fc: Mixed_4b.branch3x3_1.conv.weight
~fc: Mixed_4b.branch3x3_1.bn.weight
~fc: Mixed_4b.branch3x3_1.bn.bias
~fc: Mixed_4b.branch3x3_2.conv.weight
~fc: Mixed_4b.branch3x3_2.bn.weight
~fc: Mixed_4b.branch3x3_2.bn.bias
~fc: Mixed_4b.branch5x5_1.conv.weight
~fc: Mixed_4b.branch5x5_1.bn.weight
~fc: Mixed_4b.branch5x5_1.bn.bias
~fc: Mixed_4b.branch5x5_2.conv.weight
~fc: Mixed_4b.branch5x5_2.bn.weight
~fc: Mixed_4b.branch5x5_2.bn.bias
~fc: Mixed_4b.branch_pool.conv.weight
~fc: Mixed_4b.branch_pool.bn.weight
~fc: Mixed_4b.branch_pool.bn.bias
~fc: Mixed_4c.branch1x1.conv.weight
~fc: Mixed_4c.branch1x1.bn.weight
~fc: Mixed_4c.branch1x1.bn.bias
~fc: Mixed_4c.branch3x3_1.conv.weight
~fc: Mixed_4c.branch3x3_1.bn.weight
~fc: Mixed_4c.branch3x3_1.bn.bias
~fc: Mixed_4c.branch3x3_2.conv.weight
~fc: Mixed_4c.branch3x3_2.bn.weight
~fc: Mixed_4c.branch3x3_2.bn.bias
~fc: Mixed_4c.branch5x5_1.conv.weight
~fc: Mixed_4c.branch5x5_1.bn.weight
~fc: Mixed_4c.branch5x5_1.bn.bias
~fc: Mixed_4c.branch5x5_2.conv.weight
~fc: Mixed_4c.branch5x5_2.bn.weight
~fc: Mixed_4c.branch5x5_2.bn.bias
~fc: Mixed_4c.branch_pool.conv.weight
~fc: Mixed_4c.branch_pool.bn.weight
~fc: Mixed_4c.branch_pool.bn.bias
~fc: Mixed_4d.branch1x1.conv.weight
~fc: Mixed_4d.branch1x1.bn.weight
~fc: Mixed_4d.branch1x1.bn.bias
~fc: Mixed_4d.branch3x3_1.conv.weight
~fc: Mixed_4d.branch3x3_1.bn.weight
~fc: Mixed_4d.branch3x3_1.bn.bias
~fc: Mixed_4d.branch3x3_2.conv.weight
~fc: Mixed_4d.branch3x3_2.bn.weight
~fc: Mixed_4d.branch3x3_2.bn.bias
~fc: Mixed_4d.branch5x5_1.conv.weight
~fc: Mixed_4d.branch5x5_1.bn.weight
~fc: Mixed_4d.branch5x5_1.bn.bias
~fc: Mixed_4d.branch5x5_2.conv.weight
~fc: Mixed_4d.branch5x5_2.bn.weight
~fc: Mixed_4d.branch5x5_2.bn.bias
~fc: Mixed_4d.branch_pool.conv.weight
~fc: Mixed_4d.branch_pool.bn.weight
~fc: Mixed_4d.branch_pool.bn.bias
~fc: Mixed_4e.branch1x1.conv.weight
~fc: Mixed_4e.branch1x1.bn.weight
~fc: Mixed_4e.branch1x1.bn.bias
~fc: Mixed_4e.branch3x3_1.conv.weight
~fc: Mixed_4e.branch3x3_1.bn.weight
~fc: Mixed_4e.branch3x3_1.bn.bias
~fc: Mixed_4e.branch3x3_2.conv.weight
~fc: Mixed_4e.branch3x3_2.bn.weight
~fc: Mixed_4e.branch3x3_2.bn.bias
~fc: Mixed_4e.branch5x5_1.conv.weight
~fc: Mixed_4e.branch5x5_1.bn.weight
~fc: Mixed_4e.branch5x5_1.bn.bias
~fc: Mixed_4e.branch5x5_2.conv.weight
~fc: Mixed_4e.branch5x5_2.bn.weight
~fc: Mixed_4e.branch5x5_2.bn.bias
~fc: Mixed_4e.branch_pool.conv.weight
~fc: Mixed_4e.branch_pool.bn.weight
~fc: Mixed_4e.branch_pool.bn.bias
~fc: Mixed_5a.branch1x1.conv.weight
~fc: Mixed_5a.branch1x1.bn.weight
~fc: Mixed_5a.branch1x1.bn.bias
~fc: Mixed_5a.branch3x3_1.conv.weight
~fc: Mixed_5a.branch3x3_1.bn.weight
~fc: Mixed_5a.branch3x3_1.bn.bias
~fc: Mixed_5a.branch3x3_2.conv.weight
~fc: Mixed_5a.branch3x3_2.bn.weight
~fc: Mixed_5a.branch3x3_2.bn.bias
~fc: Mixed_5a.branch5x5_1.conv.weight
~fc: Mixed_5a.branch5x5_1.bn.weight
~fc: Mixed_5a.branch5x5_1.bn.bias
~fc: Mixed_5a.branch5x5_2.conv.weight
~fc: Mixed_5a.branch5x5_2.bn.weight
~fc: Mixed_5a.branch5x5_2.bn.bias
~fc: Mixed_5a.branch_pool.conv.weight
~fc: Mixed_5a.branch_pool.bn.weight
~fc: Mixed_5a.branch_pool.bn.bias
~fc: Mixed_5b.branch1x1.conv.weight
~fc: Mixed_5b.branch1x1.bn.weight
~fc: Mixed_5b.branch1x1.bn.bias
~fc: Mixed_5b.branch3x3_1.conv.weight
~fc: Mixed_5b.branch3x3_1.bn.weight
~fc: Mixed_5b.branch3x3_1.bn.bias
~fc: Mixed_5b.branch3x3_2.conv.weight
~fc: Mixed_5b.branch3x3_2.bn.weight
~fc: Mixed_5b.branch3x3_2.bn.bias
~fc: Mixed_5b.branch5x5_1.conv.weight
~fc: Mixed_5b.branch5x5_1.bn.weight
~fc: Mixed_5b.branch5x5_1.bn.bias
~fc: Mixed_5b.branch5x5_2.conv.weight
~fc: Mixed_5b.branch5x5_2.bn.weight
~fc: Mixed_5b.branch5x5_2.bn.bias
~fc: Mixed_5b.branch_pool.conv.weight
~fc: Mixed_5b.branch_pool.bn.weight
~fc: Mixed_5b.branch_pool.bn.bias
~fc: fc2.weight
~fc: fc2.bias
fc learning rate: 0.005
not fc learning rate: 0.005
googleNet(
  (Conv2d1): BasicConv2d(
    (conv): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
    (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d2): BasicConv2d(
    (conv): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Mixed_3a): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(4, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_3b): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(8, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_4a): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(24, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(52, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(120, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(4, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(4, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(12, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(120, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_4b): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(128, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(28, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(28, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(128, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(6, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_4c): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(128, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(12, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(12, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_4d): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(28, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(128, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(36, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(36, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_4e): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(132, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(132, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(132, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5a): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(208, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(208, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(208, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5b): InceptionModule(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(208, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(208, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(208, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(12, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (dropout_layer): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
)
epoch: 0
Train: [0/422]	Time 5.023 (5.023)	Loss 2.4017 (2.4017)	Prec@1 7.812 (7.812)	Prec@5 42.188 (42.188)
Train: [50/422]	Time 0.069 (0.170)	Loss 1.0530 (1.3390)	Prec@1 64.062 (49.479)	Prec@5 98.438 (93.229)
Train: [100/422]	Time 0.062 (0.071)	Loss 1.0556 (1.1712)	Prec@1 57.812 (55.734)	Prec@5 100.000 (96.078)
Train: [150/422]	Time 0.062 (0.066)	Loss 0.7254 (0.9644)	Prec@1 70.312 (63.859)	Prec@5 98.438 (98.172)
Train: [200/422]	Time 0.068 (0.063)	Loss 0.8086 (0.8780)	Prec@1 75.000 (67.453)	Prec@5 95.312 (98.500)
Train: [250/422]	Time 0.063 (0.063)	Loss 0.9401 (0.8438)	Prec@1 68.750 (68.516)	Prec@5 100.000 (98.641)
Train: [300/422]	Time 0.068 (0.064)	Loss 0.7526 (0.8071)	Prec@1 71.875 (69.969)	Prec@5 100.000 (98.906)
Train: [350/422]	Time 0.068 (0.069)	Loss 0.7543 (0.7764)	Prec@1 65.625 (71.344)	Prec@5 100.000 (98.844)
Train: [400/422]	Time 0.070 (0.067)	Loss 0.6506 (0.7600)	Prec@1 81.250 (71.438)	Prec@5 100.000 (98.844)
Test: [0/47]	Time 0.368 (0.368)	Loss 0.6715 (0.6715)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.015 (0.066)	Loss 0.7107 (0.6909)	Prec@1 68.750 (75.149)	Prec@5 98.438 (99.554)
Test: [40/47]	Time 0.012 (0.041)	Loss 0.5064 (0.6847)	Prec@1 82.812 (74.924)	Prec@5 100.000 (99.352)
Test: [0/40] Acc 75.067
epoch: 1
Train: [0/422]	Time 0.378 (0.378)	Loss 0.5484 (0.5484)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.051 (0.058)	Loss 0.6573 (0.6795)	Prec@1 76.562 (74.112)	Prec@5 100.000 (99.326)
Train: [100/422]	Time 0.051 (0.051)	Loss 0.7738 (0.6830)	Prec@1 71.875 (74.344)	Prec@5 100.000 (99.375)
Train: [150/422]	Time 0.069 (0.055)	Loss 0.6781 (0.6896)	Prec@1 75.000 (74.562)	Prec@5 100.000 (99.297)
Train: [200/422]	Time 0.086 (0.065)	Loss 0.7006 (0.7016)	Prec@1 67.188 (73.906)	Prec@5 100.000 (99.188)
Train: [250/422]	Time 0.069 (0.073)	Loss 0.6016 (0.6794)	Prec@1 78.125 (75.062)	Prec@5 98.438 (99.219)
Train: [300/422]	Time 0.068 (0.071)	Loss 0.6008 (0.6412)	Prec@1 75.000 (76.453)	Prec@5 100.000 (99.281)
Train: [350/422]	Time 0.077 (0.069)	Loss 0.6873 (0.6135)	Prec@1 73.438 (77.281)	Prec@5 96.875 (99.391)
Train: [400/422]	Time 0.070 (0.070)	Loss 0.4809 (0.6059)	Prec@1 82.812 (77.641)	Prec@5 100.000 (99.484)
Test: [0/47]	Time 0.379 (0.379)	Loss 0.7114 (0.7114)	Prec@1 67.188 (67.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.034)	Loss 1.0270 (0.7903)	Prec@1 67.188 (72.545)	Prec@5 100.000 (99.554)
Test: [40/47]	Time 0.014 (0.025)	Loss 0.8072 (0.8088)	Prec@1 71.875 (73.018)	Prec@5 100.000 (99.314)
Test: [1/40] Acc 73.167
epoch: 2
Train: [0/422]	Time 0.416 (0.416)	Loss 0.6888 (0.6888)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.082 (0.087)	Loss 0.4081 (0.5800)	Prec@1 84.375 (79.167)	Prec@5 100.000 (99.449)
Train: [100/422]	Time 0.069 (0.076)	Loss 0.9498 (0.5943)	Prec@1 67.188 (78.766)	Prec@5 100.000 (99.453)
Train: [150/422]	Time 0.070 (0.070)	Loss 0.7076 (0.6041)	Prec@1 78.125 (77.984)	Prec@5 100.000 (99.438)
Train: [200/422]	Time 0.069 (0.070)	Loss 0.5725 (0.5852)	Prec@1 78.125 (78.328)	Prec@5 100.000 (99.453)
Train: [250/422]	Time 0.069 (0.071)	Loss 0.6721 (0.5730)	Prec@1 76.562 (79.047)	Prec@5 98.438 (99.547)
Train: [300/422]	Time 0.068 (0.070)	Loss 0.6624 (0.5754)	Prec@1 75.000 (79.156)	Prec@5 98.438 (99.438)
Train: [350/422]	Time 0.069 (0.070)	Loss 0.5699 (0.5762)	Prec@1 79.688 (78.953)	Prec@5 100.000 (99.406)
Train: [400/422]	Time 0.067 (0.071)	Loss 0.3505 (0.5588)	Prec@1 87.500 (79.297)	Prec@5 100.000 (99.469)
Test: [0/47]	Time 0.371 (0.371)	Loss 0.3798 (0.3798)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.5355 (0.4320)	Prec@1 78.125 (83.482)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.3513 (0.4302)	Prec@1 85.938 (83.727)	Prec@5 100.000 (99.771)
Test: [2/40] Acc 83.700
epoch: 3
Train: [0/422]	Time 0.403 (0.403)	Loss 0.5046 (0.5046)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.067 (0.071)	Loss 0.5472 (0.5218)	Prec@1 87.500 (81.434)	Prec@5 98.438 (99.449)
Train: [100/422]	Time 0.064 (0.064)	Loss 0.6082 (0.5363)	Prec@1 70.312 (80.656)	Prec@5 100.000 (99.469)
Train: [150/422]	Time 0.064 (0.063)	Loss 0.4588 (0.5216)	Prec@1 84.375 (81.016)	Prec@5 100.000 (99.562)
Train: [200/422]	Time 0.075 (0.068)	Loss 0.5814 (0.5068)	Prec@1 76.562 (81.422)	Prec@5 100.000 (99.547)
Train: [250/422]	Time 0.066 (0.071)	Loss 0.7398 (0.5318)	Prec@1 76.562 (80.281)	Prec@5 96.875 (99.500)
Train: [300/422]	Time 0.074 (0.069)	Loss 0.7280 (0.5375)	Prec@1 75.000 (80.094)	Prec@5 96.875 (99.547)
Train: [350/422]	Time 0.068 (0.070)	Loss 0.5463 (0.5163)	Prec@1 79.688 (80.875)	Prec@5 100.000 (99.594)
Train: [400/422]	Time 0.070 (0.070)	Loss 0.5865 (0.5117)	Prec@1 81.250 (80.969)	Prec@5 98.438 (99.625)
Test: [0/47]	Time 0.352 (0.352)	Loss 0.5192 (0.5192)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.030)	Loss 0.4987 (0.4535)	Prec@1 76.562 (82.812)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.018 (0.024)	Loss 0.3491 (0.4316)	Prec@1 85.938 (83.689)	Prec@5 100.000 (99.886)
Test: [3/40] Acc 83.667
epoch: 4
Train: [0/422]	Time 0.393 (0.393)	Loss 0.4874 (0.4874)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.085 (0.078)	Loss 0.5198 (0.4913)	Prec@1 82.812 (81.801)	Prec@5 98.438 (99.663)
Train: [100/422]	Time 0.067 (0.077)	Loss 0.5626 (0.4917)	Prec@1 81.250 (81.875)	Prec@5 100.000 (99.641)
Train: [150/422]	Time 0.068 (0.077)	Loss 0.5837 (0.4942)	Prec@1 81.250 (81.969)	Prec@5 100.000 (99.656)
Train: [200/422]	Time 0.070 (0.072)	Loss 0.4264 (0.4974)	Prec@1 87.500 (81.641)	Prec@5 100.000 (99.625)
Train: [250/422]	Time 0.072 (0.073)	Loss 0.3089 (0.4941)	Prec@1 92.188 (81.469)	Prec@5 100.000 (99.516)
Train: [300/422]	Time 0.070 (0.073)	Loss 0.4622 (0.4937)	Prec@1 81.250 (81.875)	Prec@5 100.000 (99.531)
Train: [350/422]	Time 0.070 (0.072)	Loss 0.3735 (0.4910)	Prec@1 89.062 (82.172)	Prec@5 100.000 (99.531)
Train: [400/422]	Time 0.069 (0.072)	Loss 0.3684 (0.4641)	Prec@1 87.500 (82.859)	Prec@5 100.000 (99.625)
Test: [0/47]	Time 0.353 (0.353)	Loss 0.3363 (0.3363)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.5017 (0.4070)	Prec@1 79.688 (84.226)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.4002 (0.3941)	Prec@1 89.062 (85.404)	Prec@5 100.000 (99.809)
Test: [4/40] Acc 85.133
epoch: 5
Train: [0/422]	Time 0.381 (0.381)	Loss 0.4276 (0.4276)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.070)	Loss 0.3632 (0.4341)	Prec@1 82.812 (83.303)	Prec@5 100.000 (99.724)
Train: [100/422]	Time 0.079 (0.065)	Loss 0.4410 (0.4710)	Prec@1 85.938 (82.828)	Prec@5 100.000 (99.625)
Train: [150/422]	Time 0.070 (0.068)	Loss 0.4514 (0.4868)	Prec@1 84.375 (82.828)	Prec@5 100.000 (99.531)
Train: [200/422]	Time 0.070 (0.072)	Loss 0.3131 (0.4695)	Prec@1 84.375 (82.922)	Prec@5 100.000 (99.562)
Train: [250/422]	Time 0.068 (0.071)	Loss 0.4832 (0.4707)	Prec@1 84.375 (82.562)	Prec@5 100.000 (99.703)
Train: [300/422]	Time 0.069 (0.069)	Loss 0.6558 (0.4623)	Prec@1 75.000 (82.906)	Prec@5 95.312 (99.734)
Train: [350/422]	Time 0.072 (0.069)	Loss 0.3082 (0.4521)	Prec@1 85.938 (83.500)	Prec@5 100.000 (99.688)
Train: [400/422]	Time 0.081 (0.073)	Loss 0.4893 (0.4524)	Prec@1 79.688 (83.172)	Prec@5 100.000 (99.734)
Test: [0/47]	Time 0.371 (0.371)	Loss 0.4504 (0.4504)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.017 (0.034)	Loss 0.5600 (0.4529)	Prec@1 79.688 (82.143)	Prec@5 100.000 (99.851)
Test: [40/47]	Time 0.012 (0.025)	Loss 0.4276 (0.4577)	Prec@1 81.250 (81.974)	Prec@5 100.000 (99.886)
Test: [5/40] Acc 81.767
epoch: 6
Train: [0/422]	Time 0.393 (0.393)	Loss 0.5602 (0.5602)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.071 (0.075)	Loss 0.5581 (0.4770)	Prec@1 81.250 (82.721)	Prec@5 98.438 (99.571)
Train: [100/422]	Time 0.086 (0.077)	Loss 0.5082 (0.4560)	Prec@1 82.812 (83.906)	Prec@5 98.438 (99.594)
Train: [150/422]	Time 0.070 (0.081)	Loss 0.5923 (0.4427)	Prec@1 81.250 (83.969)	Prec@5 96.875 (99.625)
Train: [200/422]	Time 0.068 (0.074)	Loss 0.5217 (0.4436)	Prec@1 84.375 (83.453)	Prec@5 100.000 (99.734)
Train: [250/422]	Time 0.071 (0.071)	Loss 0.4518 (0.4330)	Prec@1 85.938 (84.109)	Prec@5 100.000 (99.750)
Train: [300/422]	Time 0.070 (0.071)	Loss 0.5001 (0.4452)	Prec@1 79.688 (83.188)	Prec@5 100.000 (99.703)
Train: [350/422]	Time 0.073 (0.071)	Loss 0.2539 (0.4458)	Prec@1 92.188 (82.891)	Prec@5 100.000 (99.688)
Train: [400/422]	Time 0.085 (0.073)	Loss 0.5754 (0.4324)	Prec@1 73.438 (84.203)	Prec@5 100.000 (99.625)
Test: [0/47]	Time 0.382 (0.382)	Loss 0.3680 (0.3680)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.017 (0.035)	Loss 0.4697 (0.3565)	Prec@1 81.250 (86.607)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.016 (0.027)	Loss 0.2745 (0.3586)	Prec@1 89.062 (86.623)	Prec@5 100.000 (99.848)
Test: [6/40] Acc 86.467
epoch: 7
Train: [0/422]	Time 0.390 (0.390)	Loss 0.4084 (0.4084)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.067 (0.076)	Loss 0.5108 (0.4392)	Prec@1 82.812 (84.038)	Prec@5 100.000 (99.571)
Train: [100/422]	Time 0.065 (0.070)	Loss 0.4743 (0.4348)	Prec@1 82.812 (84.312)	Prec@5 100.000 (99.672)
Train: [150/422]	Time 0.071 (0.070)	Loss 0.4141 (0.4157)	Prec@1 81.250 (85.062)	Prec@5 100.000 (99.766)
Train: [200/422]	Time 0.083 (0.072)	Loss 0.3600 (0.4205)	Prec@1 84.375 (84.797)	Prec@5 100.000 (99.734)
Train: [250/422]	Time 0.078 (0.075)	Loss 0.3277 (0.4189)	Prec@1 89.062 (84.438)	Prec@5 100.000 (99.734)
Train: [300/422]	Time 0.076 (0.077)	Loss 0.1946 (0.4113)	Prec@1 95.312 (84.812)	Prec@5 100.000 (99.812)
Train: [350/422]	Time 0.071 (0.075)	Loss 0.3754 (0.4288)	Prec@1 84.375 (84.453)	Prec@5 100.000 (99.812)
Train: [400/422]	Time 0.087 (0.072)	Loss 0.2416 (0.4197)	Prec@1 92.188 (84.672)	Prec@5 100.000 (99.750)
Test: [0/47]	Time 0.350 (0.350)	Loss 0.5831 (0.5831)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.023 (0.034)	Loss 0.5302 (0.4883)	Prec@1 84.375 (82.515)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.015 (0.025)	Loss 0.5261 (0.4984)	Prec@1 76.562 (82.050)	Prec@5 100.000 (99.924)
Test: [7/40] Acc 81.633
epoch: 8
Train: [0/422]	Time 0.392 (0.392)	Loss 0.4132 (0.4132)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.067 (0.079)	Loss 0.2798 (0.4025)	Prec@1 93.750 (85.233)	Prec@5 100.000 (99.786)
Train: [100/422]	Time 0.070 (0.071)	Loss 0.4771 (0.4175)	Prec@1 81.250 (84.688)	Prec@5 100.000 (99.797)
Train: [150/422]	Time 0.083 (0.073)	Loss 0.2695 (0.4211)	Prec@1 90.625 (84.359)	Prec@5 100.000 (99.812)
Train: [200/422]	Time 0.076 (0.079)	Loss 0.4426 (0.4193)	Prec@1 84.375 (84.656)	Prec@5 100.000 (99.703)
Train: [250/422]	Time 0.073 (0.076)	Loss 0.3845 (0.4211)	Prec@1 87.500 (84.953)	Prec@5 100.000 (99.688)
Train: [300/422]	Time 0.070 (0.072)	Loss 0.4758 (0.4252)	Prec@1 82.812 (84.703)	Prec@5 100.000 (99.688)
Train: [350/422]	Time 0.071 (0.072)	Loss 0.2972 (0.4111)	Prec@1 92.188 (85.219)	Prec@5 100.000 (99.734)
Train: [400/422]	Time 0.069 (0.071)	Loss 0.4181 (0.3918)	Prec@1 79.688 (85.641)	Prec@5 100.000 (99.844)
Test: [0/47]	Time 0.330 (0.330)	Loss 0.3154 (0.3154)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.029)	Loss 0.4120 (0.3601)	Prec@1 82.812 (86.533)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.022)	Loss 0.2652 (0.3541)	Prec@1 92.188 (86.890)	Prec@5 100.000 (99.924)
Test: [8/40] Acc 86.667
epoch: 9
Train: [0/422]	Time 0.417 (0.417)	Loss 0.5575 (0.5575)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.070 (0.077)	Loss 0.4056 (0.4075)	Prec@1 81.250 (85.263)	Prec@5 98.438 (99.632)
Train: [100/422]	Time 0.063 (0.068)	Loss 0.3319 (0.3963)	Prec@1 90.625 (85.672)	Prec@5 100.000 (99.688)
Train: [150/422]	Time 0.080 (0.072)	Loss 0.3905 (0.3993)	Prec@1 84.375 (85.625)	Prec@5 100.000 (99.688)
Train: [200/422]	Time 0.083 (0.075)	Loss 0.3810 (0.4024)	Prec@1 90.625 (85.344)	Prec@5 100.000 (99.703)
Train: [250/422]	Time 0.073 (0.073)	Loss 0.1950 (0.3954)	Prec@1 90.625 (85.078)	Prec@5 100.000 (99.750)
Train: [300/422]	Time 0.064 (0.072)	Loss 0.3432 (0.3963)	Prec@1 85.938 (85.156)	Prec@5 100.000 (99.797)
Train: [350/422]	Time 0.064 (0.070)	Loss 0.5049 (0.4130)	Prec@1 81.250 (85.312)	Prec@5 100.000 (99.719)
Train: [400/422]	Time 0.081 (0.070)	Loss 0.3237 (0.4044)	Prec@1 87.500 (85.625)	Prec@5 100.000 (99.578)
Test: [0/47]	Time 0.339 (0.339)	Loss 0.3922 (0.3922)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.030)	Loss 0.4401 (0.3284)	Prec@1 84.375 (87.649)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.011 (0.021)	Loss 0.3515 (0.3350)	Prec@1 87.500 (87.652)	Prec@5 100.000 (99.886)
Test: [9/40] Acc 87.133
epoch: 10
Train: [0/422]	Time 0.381 (0.381)	Loss 0.2729 (0.2729)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.077)	Loss 0.4169 (0.3873)	Prec@1 82.812 (85.754)	Prec@5 100.000 (99.724)
Train: [100/422]	Time 0.061 (0.066)	Loss 0.4398 (0.3875)	Prec@1 85.938 (86.281)	Prec@5 100.000 (99.812)
Train: [150/422]	Time 0.062 (0.062)	Loss 0.3253 (0.3900)	Prec@1 85.938 (86.031)	Prec@5 100.000 (99.828)
Train: [200/422]	Time 0.080 (0.067)	Loss 0.4555 (0.3988)	Prec@1 84.375 (84.922)	Prec@5 100.000 (99.797)
Train: [250/422]	Time 0.065 (0.070)	Loss 0.2629 (0.3896)	Prec@1 93.750 (85.641)	Prec@5 100.000 (99.812)
Train: [300/422]	Time 0.067 (0.068)	Loss 0.2618 (0.3874)	Prec@1 92.188 (85.922)	Prec@5 100.000 (99.781)
Train: [350/422]	Time 0.076 (0.068)	Loss 0.2607 (0.3916)	Prec@1 90.625 (85.797)	Prec@5 98.438 (99.781)
Train: [400/422]	Time 0.066 (0.070)	Loss 0.3671 (0.3837)	Prec@1 89.062 (86.406)	Prec@5 100.000 (99.734)
Test: [0/47]	Time 0.378 (0.378)	Loss 0.3062 (0.3062)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.033)	Loss 0.3816 (0.3740)	Prec@1 85.938 (85.863)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.024)	Loss 0.4158 (0.3735)	Prec@1 82.812 (86.166)	Prec@5 100.000 (99.886)
Test: [10/40] Acc 85.900
epoch: 11
Train: [0/422]	Time 0.407 (0.407)	Loss 0.2847 (0.2847)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.066 (0.072)	Loss 0.2645 (0.3491)	Prec@1 85.938 (87.102)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.070 (0.067)	Loss 0.3260 (0.3652)	Prec@1 85.938 (86.562)	Prec@5 100.000 (99.828)
Train: [150/422]	Time 0.071 (0.070)	Loss 0.3923 (0.3775)	Prec@1 82.812 (86.344)	Prec@5 100.000 (99.828)
Train: [200/422]	Time 0.077 (0.074)	Loss 0.3410 (0.3899)	Prec@1 87.500 (85.781)	Prec@5 100.000 (99.797)
Train: [250/422]	Time 0.072 (0.074)	Loss 0.4557 (0.3897)	Prec@1 84.375 (85.625)	Prec@5 100.000 (99.797)
Train: [300/422]	Time 0.095 (0.073)	Loss 0.4604 (0.3834)	Prec@1 87.500 (85.984)	Prec@5 100.000 (99.781)
Train: [350/422]	Time 0.071 (0.076)	Loss 0.4662 (0.3905)	Prec@1 82.812 (85.531)	Prec@5 100.000 (99.797)
Train: [400/422]	Time 0.069 (0.075)	Loss 0.2807 (0.3942)	Prec@1 89.062 (85.641)	Prec@5 100.000 (99.828)
Test: [0/47]	Time 0.351 (0.351)	Loss 0.3114 (0.3114)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.029)	Loss 0.3672 (0.3458)	Prec@1 82.812 (87.054)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.023)	Loss 0.2704 (0.3193)	Prec@1 85.938 (88.072)	Prec@5 100.000 (99.886)
Test: [11/40] Acc 87.900
epoch: 12
Train: [0/422]	Time 0.396 (0.396)	Loss 0.4854 (0.4854)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.070 (0.073)	Loss 0.4558 (0.3882)	Prec@1 81.250 (86.520)	Prec@5 100.000 (99.786)
Train: [100/422]	Time 0.070 (0.068)	Loss 0.2542 (0.3844)	Prec@1 92.188 (86.172)	Prec@5 100.000 (99.844)
Train: [150/422]	Time 0.065 (0.069)	Loss 0.2720 (0.3647)	Prec@1 89.062 (86.469)	Prec@5 100.000 (99.828)
Train: [200/422]	Time 0.065 (0.068)	Loss 0.3713 (0.3566)	Prec@1 85.938 (86.656)	Prec@5 100.000 (99.797)
Train: [250/422]	Time 0.073 (0.068)	Loss 0.2453 (0.3625)	Prec@1 92.188 (86.516)	Prec@5 100.000 (99.797)
Train: [300/422]	Time 0.069 (0.067)	Loss 0.3929 (0.3743)	Prec@1 87.500 (86.047)	Prec@5 98.438 (99.719)
Train: [350/422]	Time 0.066 (0.067)	Loss 0.2304 (0.3788)	Prec@1 93.750 (85.844)	Prec@5 100.000 (99.750)
Train: [400/422]	Time 0.067 (0.067)	Loss 0.3425 (0.3536)	Prec@1 85.938 (86.719)	Prec@5 98.438 (99.766)
Test: [0/47]	Time 0.373 (0.373)	Loss 0.2888 (0.2888)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.031)	Loss 0.3100 (0.3165)	Prec@1 85.938 (88.542)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.2636 (0.3120)	Prec@1 90.625 (88.605)	Prec@5 100.000 (99.848)
Test: [12/40] Acc 88.433
epoch: 13
Train: [0/422]	Time 0.391 (0.391)	Loss 0.2583 (0.2583)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.061 (0.068)	Loss 0.2762 (0.3581)	Prec@1 89.062 (86.979)	Prec@5 100.000 (99.786)
Train: [100/422]	Time 0.062 (0.062)	Loss 0.2001 (0.3632)	Prec@1 95.312 (87.016)	Prec@5 100.000 (99.781)
Train: [150/422]	Time 0.063 (0.062)	Loss 0.3045 (0.3586)	Prec@1 87.500 (87.266)	Prec@5 100.000 (99.781)
Train: [200/422]	Time 0.064 (0.062)	Loss 0.2464 (0.3616)	Prec@1 92.188 (86.984)	Prec@5 100.000 (99.734)
Train: [250/422]	Time 0.062 (0.066)	Loss 0.3228 (0.3640)	Prec@1 90.625 (86.875)	Prec@5 100.000 (99.719)
Train: [300/422]	Time 0.061 (0.065)	Loss 0.5338 (0.3491)	Prec@1 85.938 (87.391)	Prec@5 98.438 (99.766)
Train: [350/422]	Time 0.068 (0.065)	Loss 0.2749 (0.3566)	Prec@1 89.062 (86.922)	Prec@5 100.000 (99.734)
Train: [400/422]	Time 0.074 (0.069)	Loss 0.4194 (0.3624)	Prec@1 81.250 (86.594)	Prec@5 100.000 (99.750)
Test: [0/47]	Time 0.363 (0.363)	Loss 0.2932 (0.2932)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.031)	Loss 0.3224 (0.3071)	Prec@1 87.500 (88.318)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.3034 (0.3005)	Prec@1 85.938 (88.834)	Prec@5 100.000 (99.924)
Test: [13/40] Acc 88.600
epoch: 14
Train: [0/422]	Time 0.384 (0.384)	Loss 0.3310 (0.3310)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.060 (0.067)	Loss 0.3038 (0.3586)	Prec@1 85.938 (87.224)	Prec@5 100.000 (99.816)
Train: [100/422]	Time 0.064 (0.063)	Loss 0.2187 (0.3537)	Prec@1 92.188 (87.172)	Prec@5 100.000 (99.844)
Train: [150/422]	Time 0.065 (0.067)	Loss 0.5299 (0.3461)	Prec@1 82.812 (87.328)	Prec@5 100.000 (99.875)
Train: [200/422]	Time 0.063 (0.067)	Loss 0.4607 (0.3469)	Prec@1 84.375 (87.406)	Prec@5 98.438 (99.844)
Train: [250/422]	Time 0.074 (0.066)	Loss 0.3670 (0.3443)	Prec@1 87.500 (87.578)	Prec@5 100.000 (99.797)
Train: [300/422]	Time 0.075 (0.068)	Loss 0.3786 (0.3608)	Prec@1 84.375 (87.156)	Prec@5 100.000 (99.766)
Train: [350/422]	Time 0.073 (0.069)	Loss 0.4871 (0.3714)	Prec@1 87.500 (86.688)	Prec@5 100.000 (99.797)
Train: [400/422]	Time 0.072 (0.071)	Loss 0.5486 (0.3556)	Prec@1 79.688 (87.078)	Prec@5 98.438 (99.844)
Test: [0/47]	Time 0.371 (0.371)	Loss 0.2684 (0.2684)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.031)	Loss 0.3352 (0.3015)	Prec@1 85.938 (89.583)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.2294 (0.2931)	Prec@1 87.500 (89.520)	Prec@5 100.000 (99.924)
Test: [14/40] Acc 89.267
epoch: 15
Train: [0/422]	Time 0.380 (0.380)	Loss 0.2629 (0.2629)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.075 (0.075)	Loss 0.2510 (0.3545)	Prec@1 92.188 (86.520)	Prec@5 100.000 (99.816)
Train: [100/422]	Time 0.064 (0.070)	Loss 0.3729 (0.3574)	Prec@1 89.062 (86.578)	Prec@5 100.000 (99.781)
Train: [150/422]	Time 0.077 (0.071)	Loss 0.2525 (0.3518)	Prec@1 92.188 (87.031)	Prec@5 100.000 (99.828)
Train: [200/422]	Time 0.065 (0.070)	Loss 0.4226 (0.3483)	Prec@1 82.812 (87.578)	Prec@5 100.000 (99.859)
Train: [250/422]	Time 0.071 (0.069)	Loss 0.2623 (0.3399)	Prec@1 82.812 (87.938)	Prec@5 100.000 (99.828)
Train: [300/422]	Time 0.068 (0.068)	Loss 0.3970 (0.3240)	Prec@1 84.375 (88.031)	Prec@5 100.000 (99.828)
Train: [350/422]	Time 0.069 (0.070)	Loss 0.2408 (0.3433)	Prec@1 89.062 (87.422)	Prec@5 100.000 (99.797)
Train: [400/422]	Time 0.073 (0.069)	Loss 0.3909 (0.3561)	Prec@1 82.812 (86.797)	Prec@5 100.000 (99.812)
Test: [0/47]	Time 0.376 (0.376)	Loss 0.3608 (0.3608)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.032)	Loss 0.3368 (0.3739)	Prec@1 87.500 (86.235)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.4521 (0.3762)	Prec@1 84.375 (86.242)	Prec@5 100.000 (99.962)
Test: [15/40] Acc 85.833
epoch: 16
Train: [0/422]	Time 0.425 (0.425)	Loss 0.4769 (0.4769)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.082 (0.086)	Loss 0.2828 (0.3357)	Prec@1 95.312 (88.450)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.079 (0.081)	Loss 0.3333 (0.3344)	Prec@1 85.938 (88.125)	Prec@5 100.000 (99.891)
Train: [150/422]	Time 0.070 (0.082)	Loss 0.5026 (0.3503)	Prec@1 78.125 (87.359)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.070 (0.075)	Loss 0.3334 (0.3548)	Prec@1 87.500 (87.297)	Prec@5 100.000 (99.922)
Train: [250/422]	Time 0.067 (0.069)	Loss 0.2474 (0.3343)	Prec@1 87.500 (87.938)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.065 (0.067)	Loss 0.3403 (0.3376)	Prec@1 84.375 (87.672)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.072 (0.067)	Loss 0.3569 (0.3512)	Prec@1 82.812 (86.922)	Prec@5 100.000 (99.875)
Train: [400/422]	Time 0.082 (0.067)	Loss 0.2476 (0.3439)	Prec@1 90.625 (87.172)	Prec@5 100.000 (99.750)
Test: [0/47]	Time 0.342 (0.342)	Loss 0.2134 (0.2134)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.015 (0.031)	Loss 0.3444 (0.2971)	Prec@1 85.938 (88.690)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.015 (0.023)	Loss 0.3490 (0.2907)	Prec@1 87.500 (88.834)	Prec@5 100.000 (99.924)
Test: [16/40] Acc 88.633
epoch: 17
Train: [0/422]	Time 0.406 (0.406)	Loss 0.4046 (0.4046)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.084 (0.083)	Loss 0.1698 (0.3620)	Prec@1 96.875 (86.581)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.065 (0.075)	Loss 0.2971 (0.3387)	Prec@1 89.062 (87.281)	Prec@5 100.000 (99.844)
Train: [150/422]	Time 0.066 (0.070)	Loss 0.2670 (0.3226)	Prec@1 89.062 (87.766)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.066 (0.067)	Loss 0.1677 (0.3233)	Prec@1 93.750 (88.141)	Prec@5 100.000 (99.922)
Train: [250/422]	Time 0.075 (0.067)	Loss 0.2685 (0.3223)	Prec@1 89.062 (88.312)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.064 (0.068)	Loss 0.2128 (0.3243)	Prec@1 92.188 (88.031)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.064 (0.068)	Loss 0.3087 (0.3345)	Prec@1 89.062 (88.078)	Prec@5 100.000 (99.812)
Train: [400/422]	Time 0.071 (0.066)	Loss 0.2954 (0.3378)	Prec@1 84.375 (87.531)	Prec@5 100.000 (99.797)
Test: [0/47]	Time 0.349 (0.349)	Loss 0.2424 (0.2424)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.030)	Loss 0.3264 (0.2991)	Prec@1 84.375 (89.062)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.021)	Loss 0.2097 (0.3006)	Prec@1 90.625 (88.872)	Prec@5 100.000 (99.886)
Test: [17/40] Acc 88.733
epoch: 18
Train: [0/422]	Time 0.423 (0.423)	Loss 0.1659 (0.1659)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.078 (0.080)	Loss 0.2194 (0.3237)	Prec@1 92.188 (88.542)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.069 (0.074)	Loss 0.3236 (0.3230)	Prec@1 87.500 (88.312)	Prec@5 100.000 (99.797)
Train: [150/422]	Time 0.067 (0.072)	Loss 0.3491 (0.3260)	Prec@1 85.938 (88.031)	Prec@5 100.000 (99.781)
Train: [200/422]	Time 0.068 (0.070)	Loss 0.3407 (0.3306)	Prec@1 90.625 (87.797)	Prec@5 100.000 (99.812)
Train: [250/422]	Time 0.066 (0.070)	Loss 0.3605 (0.3312)	Prec@1 85.938 (87.578)	Prec@5 100.000 (99.844)
Train: [300/422]	Time 0.067 (0.069)	Loss 0.2467 (0.3357)	Prec@1 89.062 (87.094)	Prec@5 100.000 (99.875)
Train: [350/422]	Time 0.069 (0.069)	Loss 0.2901 (0.3224)	Prec@1 93.750 (87.922)	Prec@5 100.000 (99.859)
Train: [400/422]	Time 0.072 (0.069)	Loss 0.2622 (0.3129)	Prec@1 90.625 (88.812)	Prec@5 100.000 (99.906)
Test: [0/47]	Time 0.352 (0.352)	Loss 0.2514 (0.2514)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.030)	Loss 0.2512 (0.2973)	Prec@1 90.625 (89.435)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.025 (0.022)	Loss 0.2793 (0.2887)	Prec@1 84.375 (89.748)	Prec@5 100.000 (99.924)
Test: [18/40] Acc 89.467
epoch: 19
Train: [0/422]	Time 0.416 (0.416)	Loss 0.3057 (0.3057)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.062 (0.076)	Loss 0.2473 (0.3086)	Prec@1 92.188 (87.868)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.068 (0.067)	Loss 0.1788 (0.3120)	Prec@1 95.312 (88.062)	Prec@5 100.000 (99.906)
Train: [150/422]	Time 0.067 (0.067)	Loss 0.4717 (0.3349)	Prec@1 82.812 (87.672)	Prec@5 98.438 (99.781)
Train: [200/422]	Time 0.074 (0.068)	Loss 0.3540 (0.3388)	Prec@1 84.375 (87.547)	Prec@5 100.000 (99.812)
Train: [250/422]	Time 0.065 (0.073)	Loss 0.2560 (0.3197)	Prec@1 87.500 (88.062)	Prec@5 100.000 (99.828)
Train: [300/422]	Time 0.081 (0.077)	Loss 0.3694 (0.3156)	Prec@1 84.375 (88.328)	Prec@5 100.000 (99.844)
Train: [350/422]	Time 0.062 (0.075)	Loss 0.3199 (0.3262)	Prec@1 90.625 (88.281)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.062 (0.069)	Loss 0.1819 (0.3216)	Prec@1 90.625 (88.188)	Prec@5 100.000 (99.891)
Test: [0/47]	Time 0.355 (0.355)	Loss 0.2033 (0.2033)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.035)	Loss 0.3086 (0.2814)	Prec@1 85.938 (88.839)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.016 (0.026)	Loss 0.3399 (0.2819)	Prec@1 90.625 (89.520)	Prec@5 100.000 (99.848)
Test: [19/40] Acc 89.267
epoch: 20
Train: [0/422]	Time 0.423 (0.423)	Loss 0.2892 (0.2892)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.072 (0.078)	Loss 0.2859 (0.3281)	Prec@1 89.062 (87.653)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.081 (0.072)	Loss 0.2755 (0.3304)	Prec@1 90.625 (87.703)	Prec@5 100.000 (99.875)
Train: [150/422]	Time 0.078 (0.073)	Loss 0.3644 (0.3188)	Prec@1 90.625 (88.047)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.073 (0.074)	Loss 0.3752 (0.2954)	Prec@1 87.500 (88.984)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.066 (0.072)	Loss 0.4040 (0.2985)	Prec@1 84.375 (89.266)	Prec@5 100.000 (99.906)
Train: [300/422]	Time 0.068 (0.069)	Loss 0.4375 (0.3079)	Prec@1 87.500 (89.109)	Prec@5 98.438 (99.906)
Train: [350/422]	Time 0.066 (0.065)	Loss 0.3058 (0.3146)	Prec@1 90.625 (88.828)	Prec@5 100.000 (99.938)
Train: [400/422]	Time 0.072 (0.067)	Loss 0.2598 (0.3259)	Prec@1 90.625 (88.219)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.362 (0.362)	Loss 0.3118 (0.3118)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.032)	Loss 0.3417 (0.3011)	Prec@1 87.500 (88.914)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.023)	Loss 0.2797 (0.2921)	Prec@1 89.062 (89.558)	Prec@5 100.000 (99.962)
Test: [20/40] Acc 89.400
epoch: 21
Train: [0/422]	Time 0.401 (0.401)	Loss 0.3724 (0.3724)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.083)	Loss 0.2335 (0.3195)	Prec@1 92.188 (87.960)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.069 (0.074)	Loss 0.2708 (0.3075)	Prec@1 90.625 (88.797)	Prec@5 100.000 (99.922)
Train: [150/422]	Time 0.078 (0.071)	Loss 0.3505 (0.3075)	Prec@1 87.500 (88.891)	Prec@5 100.000 (99.922)
Train: [200/422]	Time 0.068 (0.071)	Loss 0.3842 (0.3085)	Prec@1 89.062 (88.812)	Prec@5 100.000 (99.859)
Train: [250/422]	Time 0.079 (0.072)	Loss 0.1399 (0.3146)	Prec@1 95.312 (88.703)	Prec@5 100.000 (99.875)
Train: [300/422]	Time 0.077 (0.076)	Loss 0.4261 (0.3101)	Prec@1 84.375 (88.453)	Prec@5 100.000 (99.875)
Train: [350/422]	Time 0.072 (0.074)	Loss 0.2676 (0.2908)	Prec@1 89.062 (89.266)	Prec@5 100.000 (99.859)
Train: [400/422]	Time 0.062 (0.066)	Loss 0.3334 (0.2971)	Prec@1 90.625 (89.547)	Prec@5 100.000 (99.844)
Test: [0/47]	Time 0.342 (0.342)	Loss 0.2591 (0.2591)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.031)	Loss 0.3427 (0.2767)	Prec@1 84.375 (90.104)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.2443 (0.2717)	Prec@1 92.188 (90.511)	Prec@5 100.000 (99.924)
Test: [21/40] Acc 90.367
epoch: 22
Train: [0/422]	Time 0.407 (0.407)	Loss 0.4223 (0.4223)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.071 (0.072)	Loss 0.2386 (0.2837)	Prec@1 93.750 (89.798)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.066 (0.068)	Loss 0.3994 (0.2975)	Prec@1 84.375 (89.203)	Prec@5 100.000 (99.828)
Train: [150/422]	Time 0.067 (0.067)	Loss 0.2058 (0.3205)	Prec@1 92.188 (88.391)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.064 (0.063)	Loss 0.2287 (0.3156)	Prec@1 90.625 (88.359)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.076 (0.066)	Loss 0.1719 (0.3032)	Prec@1 93.750 (88.688)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.062 (0.070)	Loss 0.2080 (0.3049)	Prec@1 92.188 (88.969)	Prec@5 100.000 (99.891)
Train: [350/422]	Time 0.062 (0.067)	Loss 0.2263 (0.3080)	Prec@1 90.625 (88.922)	Prec@5 100.000 (99.828)
Train: [400/422]	Time 0.061 (0.062)	Loss 0.2372 (0.3037)	Prec@1 92.188 (89.203)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.369 (0.369)	Loss 0.2293 (0.2293)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.017 (0.034)	Loss 0.3839 (0.2927)	Prec@1 87.500 (89.211)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.012 (0.024)	Loss 0.2484 (0.2797)	Prec@1 89.062 (90.091)	Prec@5 100.000 (99.886)
Test: [22/40] Acc 89.767
epoch: 23
Train: [0/422]	Time 0.412 (0.412)	Loss 0.2067 (0.2067)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.078)	Loss 0.3201 (0.3102)	Prec@1 93.750 (88.756)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.072 (0.070)	Loss 0.2711 (0.3004)	Prec@1 89.062 (89.219)	Prec@5 100.000 (99.922)
Train: [150/422]	Time 0.072 (0.071)	Loss 0.3404 (0.2846)	Prec@1 89.062 (89.859)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.069 (0.074)	Loss 0.1692 (0.2942)	Prec@1 93.750 (89.484)	Prec@5 100.000 (99.859)
Train: [250/422]	Time 0.063 (0.070)	Loss 0.1353 (0.3053)	Prec@1 95.312 (89.016)	Prec@5 100.000 (99.812)
Train: [300/422]	Time 0.071 (0.069)	Loss 0.2552 (0.3067)	Prec@1 87.500 (88.891)	Prec@5 100.000 (99.875)
Train: [350/422]	Time 0.062 (0.068)	Loss 0.3174 (0.3168)	Prec@1 90.625 (88.516)	Prec@5 100.000 (99.859)
Train: [400/422]	Time 0.065 (0.066)	Loss 0.4079 (0.3101)	Prec@1 85.938 (88.906)	Prec@5 100.000 (99.812)
Test: [0/47]	Time 0.351 (0.351)	Loss 0.2111 (0.2111)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.031)	Loss 0.3208 (0.2716)	Prec@1 87.500 (89.509)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.023)	Loss 0.1830 (0.2724)	Prec@1 93.750 (89.901)	Prec@5 100.000 (99.924)
Test: [23/40] Acc 89.733
epoch: 24
Train: [0/422]	Time 0.420 (0.420)	Loss 0.2193 (0.2193)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.063 (0.073)	Loss 0.2199 (0.2715)	Prec@1 90.625 (89.890)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.064 (0.065)	Loss 0.1623 (0.2785)	Prec@1 95.312 (89.562)	Prec@5 100.000 (99.922)
Train: [150/422]	Time 0.079 (0.066)	Loss 0.4524 (0.2842)	Prec@1 89.062 (89.328)	Prec@5 100.000 (99.938)
Train: [200/422]	Time 0.070 (0.070)	Loss 0.2714 (0.2880)	Prec@1 90.625 (89.406)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.069 (0.071)	Loss 0.2409 (0.3006)	Prec@1 89.062 (88.938)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.066 (0.070)	Loss 0.2050 (0.3038)	Prec@1 90.625 (88.781)	Prec@5 100.000 (99.891)
Train: [350/422]	Time 0.063 (0.067)	Loss 0.2308 (0.2858)	Prec@1 93.750 (89.578)	Prec@5 100.000 (99.891)
Train: [400/422]	Time 0.063 (0.063)	Loss 0.3960 (0.2881)	Prec@1 81.250 (89.438)	Prec@5 100.000 (99.812)
Test: [0/47]	Time 0.356 (0.356)	Loss 0.2341 (0.2341)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.030)	Loss 0.2751 (0.2657)	Prec@1 89.062 (90.625)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.013 (0.022)	Loss 0.3479 (0.2752)	Prec@1 87.500 (90.396)	Prec@5 100.000 (99.962)
Test: [24/40] Acc 90.100
epoch: 25
Train: [0/422]	Time 0.396 (0.396)	Loss 0.2032 (0.2032)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.068 (0.079)	Loss 0.2482 (0.2872)	Prec@1 93.750 (89.491)	Prec@5 100.000 (99.755)
Train: [100/422]	Time 0.079 (0.072)	Loss 0.3195 (0.2899)	Prec@1 85.938 (89.094)	Prec@5 100.000 (99.844)
Train: [150/422]	Time 0.070 (0.071)	Loss 0.3322 (0.2855)	Prec@1 81.250 (89.062)	Prec@5 100.000 (99.938)
Train: [200/422]	Time 0.065 (0.070)	Loss 0.2654 (0.2835)	Prec@1 87.500 (89.297)	Prec@5 100.000 (99.906)
Train: [250/422]	Time 0.062 (0.066)	Loss 0.3155 (0.2942)	Prec@1 89.062 (88.984)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.061 (0.062)	Loss 0.2813 (0.3017)	Prec@1 89.062 (88.547)	Prec@5 98.438 (99.938)
Train: [350/422]	Time 0.061 (0.063)	Loss 0.3398 (0.3059)	Prec@1 92.188 (88.438)	Prec@5 100.000 (99.906)
Train: [400/422]	Time 0.061 (0.062)	Loss 0.2931 (0.2970)	Prec@1 87.500 (89.078)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.360 (0.360)	Loss 0.2129 (0.2129)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.031)	Loss 0.2695 (0.2711)	Prec@1 90.625 (89.583)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.013 (0.022)	Loss 0.2868 (0.2726)	Prec@1 89.062 (90.015)	Prec@5 100.000 (99.886)
Test: [25/40] Acc 89.800
epoch: 26
Train: [0/422]	Time 0.412 (0.412)	Loss 0.3952 (0.3952)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.071 (0.079)	Loss 0.4555 (0.2503)	Prec@1 85.938 (90.717)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.083 (0.074)	Loss 0.3558 (0.2755)	Prec@1 85.938 (89.938)	Prec@5 100.000 (99.906)
Train: [150/422]	Time 0.085 (0.077)	Loss 0.4503 (0.2964)	Prec@1 85.938 (89.281)	Prec@5 100.000 (99.891)
Train: [200/422]	Time 0.093 (0.080)	Loss 0.3388 (0.2830)	Prec@1 87.500 (89.688)	Prec@5 100.000 (99.891)
Train: [250/422]	Time 0.085 (0.082)	Loss 0.3050 (0.2858)	Prec@1 90.625 (89.719)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.066 (0.081)	Loss 0.3033 (0.2943)	Prec@1 87.500 (89.344)	Prec@5 98.438 (99.859)
Train: [350/422]	Time 0.062 (0.071)	Loss 0.1854 (0.2949)	Prec@1 92.188 (89.078)	Prec@5 100.000 (99.750)
Train: [400/422]	Time 0.069 (0.065)	Loss 0.2027 (0.2929)	Prec@1 93.750 (89.344)	Prec@5 100.000 (99.797)
Test: [0/47]	Time 0.352 (0.352)	Loss 0.1898 (0.1898)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.012 (0.030)	Loss 0.2503 (0.2615)	Prec@1 85.938 (90.030)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.2714 (0.2724)	Prec@1 90.625 (90.396)	Prec@5 100.000 (99.962)
Test: [26/40] Acc 90.100
epoch: 27
Train: [0/422]	Time 0.388 (0.388)	Loss 0.2645 (0.2645)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.074 (0.070)	Loss 0.4558 (0.2662)	Prec@1 79.688 (90.165)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.075 (0.067)	Loss 0.2617 (0.2785)	Prec@1 90.625 (89.672)	Prec@5 100.000 (99.906)
Train: [150/422]	Time 0.072 (0.071)	Loss 0.3277 (0.2902)	Prec@1 87.500 (89.094)	Prec@5 100.000 (99.875)
Train: [200/422]	Time 0.069 (0.071)	Loss 0.2609 (0.2830)	Prec@1 93.750 (89.484)	Prec@5 100.000 (99.891)
Train: [250/422]	Time 0.066 (0.071)	Loss 0.2772 (0.2748)	Prec@1 89.062 (90.047)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.071 (0.071)	Loss 0.1917 (0.2791)	Prec@1 90.625 (90.094)	Prec@5 100.000 (99.906)
Train: [350/422]	Time 0.070 (0.071)	Loss 0.2448 (0.2804)	Prec@1 92.188 (90.062)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.073 (0.072)	Loss 0.1394 (0.2774)	Prec@1 92.188 (90.000)	Prec@5 100.000 (99.969)
Test: [0/47]	Time 0.359 (0.359)	Loss 0.1717 (0.1717)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.034)	Loss 0.2590 (0.2672)	Prec@1 87.500 (90.476)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.013 (0.025)	Loss 0.2093 (0.2675)	Prec@1 92.188 (90.625)	Prec@5 100.000 (99.924)
Test: [27/40] Acc 90.667
epoch: 28
Train: [0/422]	Time 0.393 (0.393)	Loss 0.4586 (0.4586)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.079)	Loss 0.2045 (0.2672)	Prec@1 85.938 (90.502)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.075 (0.071)	Loss 0.2009 (0.2714)	Prec@1 92.188 (90.234)	Prec@5 100.000 (99.938)
Train: [150/422]	Time 0.068 (0.069)	Loss 0.2893 (0.2824)	Prec@1 87.500 (89.562)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.073 (0.070)	Loss 0.4904 (0.2893)	Prec@1 87.500 (89.547)	Prec@5 100.000 (99.906)
Train: [250/422]	Time 0.062 (0.069)	Loss 0.0638 (0.2897)	Prec@1 98.438 (89.703)	Prec@5 100.000 (99.922)
Train: [300/422]	Time 0.065 (0.066)	Loss 0.1228 (0.2825)	Prec@1 96.875 (89.641)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.065 (0.066)	Loss 0.2489 (0.2744)	Prec@1 92.188 (90.078)	Prec@5 100.000 (99.938)
Train: [400/422]	Time 0.071 (0.069)	Loss 0.2288 (0.2664)	Prec@1 89.062 (90.266)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.378 (0.378)	Loss 0.1949 (0.1949)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.3294 (0.3027)	Prec@1 85.938 (88.914)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.2742 (0.3177)	Prec@1 92.188 (89.367)	Prec@5 100.000 (99.886)
Test: [28/40] Acc 89.133
epoch: 29
Train: [0/422]	Time 0.409 (0.409)	Loss 0.0995 (0.0995)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.064 (0.076)	Loss 0.2912 (0.2735)	Prec@1 84.375 (89.614)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.062 (0.067)	Loss 0.3130 (0.2825)	Prec@1 90.625 (89.406)	Prec@5 100.000 (99.875)
Train: [150/422]	Time 0.063 (0.063)	Loss 0.3597 (0.2764)	Prec@1 90.625 (89.859)	Prec@5 100.000 (99.922)
Train: [200/422]	Time 0.062 (0.062)	Loss 0.1544 (0.2712)	Prec@1 95.312 (89.906)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.063 (0.062)	Loss 0.1830 (0.2756)	Prec@1 93.750 (89.594)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.074 (0.068)	Loss 0.3317 (0.2673)	Prec@1 92.188 (90.094)	Prec@5 98.438 (99.969)
Train: [350/422]	Time 0.071 (0.070)	Loss 0.1628 (0.2656)	Prec@1 95.312 (90.219)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.061 (0.068)	Loss 0.3377 (0.2662)	Prec@1 87.500 (89.891)	Prec@5 98.438 (99.891)
Test: [0/47]	Time 0.369 (0.369)	Loss 0.2293 (0.2293)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.3906 (0.2851)	Prec@1 84.375 (90.030)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.2910 (0.2807)	Prec@1 87.500 (89.977)	Prec@5 100.000 (99.962)
Test: [29/40] Acc 89.933
epoch: 30
Train: [0/422]	Time 0.421 (0.421)	Loss 0.1951 (0.1951)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.060 (0.071)	Loss 0.4219 (0.2842)	Prec@1 82.812 (89.920)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.067 (0.064)	Loss 0.2085 (0.2865)	Prec@1 93.750 (89.344)	Prec@5 100.000 (99.938)
Train: [150/422]	Time 0.061 (0.067)	Loss 0.3327 (0.2795)	Prec@1 90.625 (89.438)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.072 (0.072)	Loss 0.3245 (0.2782)	Prec@1 87.500 (89.750)	Prec@5 100.000 (99.891)
Train: [250/422]	Time 0.067 (0.072)	Loss 0.3064 (0.2746)	Prec@1 87.500 (89.766)	Prec@5 100.000 (99.844)
Train: [300/422]	Time 0.080 (0.074)	Loss 0.1423 (0.2671)	Prec@1 93.750 (90.266)	Prec@5 100.000 (99.859)
Train: [350/422]	Time 0.062 (0.071)	Loss 0.1932 (0.2750)	Prec@1 92.188 (90.203)	Prec@5 100.000 (99.906)
Train: [400/422]	Time 0.064 (0.065)	Loss 0.3789 (0.2751)	Prec@1 87.500 (89.969)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.355 (0.355)	Loss 0.2040 (0.2040)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.032)	Loss 0.2635 (0.2552)	Prec@1 90.625 (90.848)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.013 (0.023)	Loss 0.2346 (0.2471)	Prec@1 92.188 (91.273)	Prec@5 100.000 (99.962)
Test: [30/40] Acc 90.933
epoch: 31
Train: [0/422]	Time 0.418 (0.418)	Loss 0.2088 (0.2088)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.070 (0.087)	Loss 0.3068 (0.2580)	Prec@1 89.062 (90.533)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.064 (0.075)	Loss 0.3412 (0.2620)	Prec@1 87.500 (90.016)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.062 (0.067)	Loss 0.2074 (0.2559)	Prec@1 93.750 (90.344)	Prec@5 100.000 (99.938)
Train: [200/422]	Time 0.062 (0.063)	Loss 0.2315 (0.2456)	Prec@1 90.625 (91.266)	Prec@5 100.000 (99.906)
Train: [250/422]	Time 0.080 (0.066)	Loss 0.2644 (0.2733)	Prec@1 85.938 (90.250)	Prec@5 100.000 (99.891)
Train: [300/422]	Time 0.069 (0.070)	Loss 0.3028 (0.2858)	Prec@1 85.938 (90.031)	Prec@5 100.000 (99.938)
Train: [350/422]	Time 0.069 (0.072)	Loss 0.3276 (0.2699)	Prec@1 82.812 (90.312)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.079 (0.072)	Loss 0.2041 (0.2750)	Prec@1 90.625 (89.656)	Prec@5 100.000 (99.953)
Test: [0/47]	Time 0.358 (0.358)	Loss 0.2130 (0.2130)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.031)	Loss 0.2245 (0.2876)	Prec@1 89.062 (90.179)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.022)	Loss 0.2436 (0.2724)	Prec@1 89.062 (91.044)	Prec@5 100.000 (99.924)
Test: [31/40] Acc 90.967
epoch: 32
Train: [0/422]	Time 0.374 (0.374)	Loss 0.3338 (0.3338)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.061 (0.072)	Loss 0.2855 (0.2558)	Prec@1 89.062 (90.319)	Prec@5 100.000 (99.847)
Train: [100/422]	Time 0.072 (0.068)	Loss 0.2475 (0.2633)	Prec@1 93.750 (90.234)	Prec@5 100.000 (99.875)
Train: [150/422]	Time 0.070 (0.071)	Loss 0.2104 (0.2619)	Prec@1 92.188 (90.359)	Prec@5 100.000 (99.922)
Train: [200/422]	Time 0.070 (0.071)	Loss 0.3036 (0.2569)	Prec@1 85.938 (90.016)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.073 (0.070)	Loss 0.1293 (0.2524)	Prec@1 96.875 (90.328)	Prec@5 100.000 (99.938)
Train: [300/422]	Time 0.063 (0.068)	Loss 0.2838 (0.2581)	Prec@1 85.938 (90.594)	Prec@5 100.000 (99.922)
Train: [350/422]	Time 0.064 (0.064)	Loss 0.3446 (0.2760)	Prec@1 90.625 (90.062)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.067 (0.067)	Loss 0.2227 (0.2653)	Prec@1 92.188 (90.281)	Prec@5 100.000 (99.906)
Test: [0/47]	Time 0.368 (0.368)	Loss 0.1890 (0.1890)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.031)	Loss 0.2550 (0.2485)	Prec@1 87.500 (91.220)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.013 (0.022)	Loss 0.2234 (0.2560)	Prec@1 92.188 (91.463)	Prec@5 100.000 (99.962)
Test: [32/40] Acc 91.100
epoch: 33
Train: [0/422]	Time 0.397 (0.397)	Loss 0.3519 (0.3519)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Train: [50/422]	Time 0.070 (0.068)	Loss 0.3080 (0.2599)	Prec@1 89.062 (89.859)	Prec@5 100.000 (99.877)
Train: [100/422]	Time 0.070 (0.066)	Loss 0.2152 (0.2566)	Prec@1 89.062 (90.297)	Prec@5 100.000 (99.859)
Train: [150/422]	Time 0.069 (0.070)	Loss 0.2503 (0.2482)	Prec@1 90.625 (91.062)	Prec@5 100.000 (99.906)
Train: [200/422]	Time 0.072 (0.071)	Loss 0.1574 (0.2455)	Prec@1 96.875 (90.984)	Prec@5 100.000 (99.938)
Train: [250/422]	Time 0.070 (0.072)	Loss 0.2537 (0.2612)	Prec@1 90.625 (90.203)	Prec@5 100.000 (99.906)
Train: [300/422]	Time 0.071 (0.071)	Loss 0.3203 (0.2707)	Prec@1 89.062 (89.906)	Prec@5 100.000 (99.953)
Train: [350/422]	Time 0.069 (0.069)	Loss 0.2825 (0.2736)	Prec@1 84.375 (90.062)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.062 (0.067)	Loss 0.2678 (0.2777)	Prec@1 90.625 (89.875)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.354 (0.354)	Loss 0.2240 (0.2240)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.2287 (0.2708)	Prec@1 90.625 (89.955)	Prec@5 100.000 (99.926)
Test: [40/47]	Time 0.013 (0.023)	Loss 0.2941 (0.2783)	Prec@1 92.188 (90.168)	Prec@5 100.000 (99.924)
Test: [33/40] Acc 90.100
epoch: 34
Train: [0/422]	Time 0.399 (0.399)	Loss 0.1013 (0.1013)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.075)	Loss 0.2592 (0.2662)	Prec@1 93.750 (89.645)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.071 (0.069)	Loss 0.1604 (0.2640)	Prec@1 96.875 (89.922)	Prec@5 100.000 (99.875)
Train: [150/422]	Time 0.070 (0.070)	Loss 0.2889 (0.2713)	Prec@1 90.625 (89.828)	Prec@5 100.000 (99.844)
Train: [200/422]	Time 0.068 (0.070)	Loss 0.1806 (0.2658)	Prec@1 90.625 (90.000)	Prec@5 100.000 (99.859)
Train: [250/422]	Time 0.071 (0.070)	Loss 0.2051 (0.2572)	Prec@1 92.188 (90.656)	Prec@5 100.000 (99.891)
Train: [300/422]	Time 0.070 (0.073)	Loss 0.2039 (0.2592)	Prec@1 93.750 (90.562)	Prec@5 98.438 (99.922)
Train: [350/422]	Time 0.070 (0.073)	Loss 0.2415 (0.2480)	Prec@1 90.625 (90.641)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.081 (0.076)	Loss 0.1510 (0.2560)	Prec@1 93.750 (90.516)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.360 (0.360)	Loss 0.2415 (0.2415)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.030)	Loss 0.2461 (0.2775)	Prec@1 93.750 (89.807)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.023)	Loss 0.2495 (0.2583)	Prec@1 90.625 (90.892)	Prec@5 100.000 (99.962)
Test: [34/40] Acc 90.667
epoch: 35
Train: [0/422]	Time 0.399 (0.399)	Loss 0.1868 (0.1868)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.071 (0.073)	Loss 0.2052 (0.2549)	Prec@1 92.188 (90.227)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.072 (0.068)	Loss 0.1968 (0.2568)	Prec@1 92.188 (90.359)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.064 (0.071)	Loss 0.2769 (0.2538)	Prec@1 90.625 (90.641)	Prec@5 100.000 (99.969)
Train: [200/422]	Time 0.073 (0.073)	Loss 0.3217 (0.2512)	Prec@1 89.062 (90.562)	Prec@5 100.000 (99.891)
Train: [250/422]	Time 0.070 (0.072)	Loss 0.2705 (0.2601)	Prec@1 93.750 (90.406)	Prec@5 100.000 (99.859)
Train: [300/422]	Time 0.068 (0.071)	Loss 0.2353 (0.2711)	Prec@1 89.062 (89.953)	Prec@5 100.000 (99.906)
Train: [350/422]	Time 0.066 (0.072)	Loss 0.1842 (0.2638)	Prec@1 93.750 (90.016)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.076 (0.075)	Loss 0.2581 (0.2595)	Prec@1 89.062 (90.266)	Prec@5 100.000 (99.891)
Test: [0/47]	Time 0.370 (0.370)	Loss 0.2202 (0.2202)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.015 (0.033)	Loss 0.2478 (0.2594)	Prec@1 90.625 (90.104)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.024)	Loss 0.2004 (0.2624)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [35/40] Acc 90.667
epoch: 36
Train: [0/422]	Time 0.399 (0.399)	Loss 0.1495 (0.1495)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.067 (0.074)	Loss 0.2256 (0.2506)	Prec@1 93.750 (90.686)	Prec@5 100.000 (99.969)
Train: [100/422]	Time 0.072 (0.069)	Loss 0.3054 (0.2504)	Prec@1 85.938 (90.766)	Prec@5 100.000 (99.953)
Train: [150/422]	Time 0.070 (0.071)	Loss 0.2493 (0.2469)	Prec@1 89.062 (90.641)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.070 (0.070)	Loss 0.3337 (0.2606)	Prec@1 87.500 (90.203)	Prec@5 100.000 (99.953)
Train: [250/422]	Time 0.070 (0.070)	Loss 0.3040 (0.2725)	Prec@1 92.188 (90.047)	Prec@5 100.000 (99.891)
Train: [300/422]	Time 0.068 (0.069)	Loss 0.1337 (0.2632)	Prec@1 93.750 (90.312)	Prec@5 100.000 (99.906)
Train: [350/422]	Time 0.084 (0.068)	Loss 0.2289 (0.2534)	Prec@1 89.062 (90.734)	Prec@5 100.000 (99.891)
Train: [400/422]	Time 0.069 (0.075)	Loss 0.3201 (0.2496)	Prec@1 89.062 (90.656)	Prec@5 100.000 (99.875)
Test: [0/47]	Time 0.378 (0.378)	Loss 0.2528 (0.2528)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.013 (0.032)	Loss 0.2686 (0.2726)	Prec@1 87.500 (89.881)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.023)	Loss 0.2091 (0.2643)	Prec@1 90.625 (90.549)	Prec@5 100.000 (99.962)
Test: [36/40] Acc 90.400
epoch: 37
Train: [0/422]	Time 0.417 (0.417)	Loss 0.3282 (0.3282)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.060 (0.073)	Loss 0.2526 (0.2458)	Prec@1 92.188 (90.931)	Prec@5 100.000 (99.908)
Train: [100/422]	Time 0.059 (0.065)	Loss 0.0995 (0.2408)	Prec@1 98.438 (91.109)	Prec@5 100.000 (99.938)
Train: [150/422]	Time 0.069 (0.065)	Loss 0.2302 (0.2462)	Prec@1 92.188 (90.797)	Prec@5 100.000 (99.984)
Train: [200/422]	Time 0.071 (0.068)	Loss 0.3964 (0.2508)	Prec@1 89.062 (90.484)	Prec@5 98.438 (99.969)
Train: [250/422]	Time 0.084 (0.073)	Loss 0.2236 (0.2507)	Prec@1 90.625 (90.750)	Prec@5 100.000 (99.953)
Train: [300/422]	Time 0.069 (0.076)	Loss 0.2160 (0.2518)	Prec@1 92.188 (90.922)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.076 (0.073)	Loss 0.3186 (0.2494)	Prec@1 85.938 (90.531)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.069 (0.071)	Loss 0.2825 (0.2499)	Prec@1 87.500 (90.531)	Prec@5 100.000 (99.953)
Test: [0/47]	Time 0.376 (0.376)	Loss 0.2464 (0.2464)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.016 (0.033)	Loss 0.2511 (0.2623)	Prec@1 90.625 (90.774)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.014 (0.024)	Loss 0.4048 (0.2699)	Prec@1 87.500 (90.320)	Prec@5 100.000 (99.962)
Test: [37/40] Acc 90.000
epoch: 38
Train: [0/422]	Time 0.437 (0.437)	Loss 0.4493 (0.4493)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.069 (0.077)	Loss 0.2115 (0.2526)	Prec@1 90.625 (90.870)	Prec@5 100.000 (99.939)
Train: [100/422]	Time 0.072 (0.070)	Loss 0.4474 (0.2444)	Prec@1 82.812 (91.094)	Prec@5 100.000 (99.922)
Train: [150/422]	Time 0.069 (0.071)	Loss 0.2246 (0.2429)	Prec@1 90.625 (90.797)	Prec@5 100.000 (99.953)
Train: [200/422]	Time 0.075 (0.073)	Loss 0.2411 (0.2353)	Prec@1 92.188 (90.844)	Prec@5 100.000 (99.984)
Train: [250/422]	Time 0.072 (0.073)	Loss 0.1579 (0.2337)	Prec@1 93.750 (91.266)	Prec@5 100.000 (99.984)
Train: [300/422]	Time 0.069 (0.072)	Loss 0.3706 (0.2521)	Prec@1 84.375 (90.953)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.068 (0.070)	Loss 0.2208 (0.2614)	Prec@1 90.625 (90.344)	Prec@5 100.000 (99.922)
Train: [400/422]	Time 0.076 (0.069)	Loss 0.2821 (0.2546)	Prec@1 90.625 (90.641)	Prec@5 100.000 (99.922)
Test: [0/47]	Time 0.362 (0.362)	Loss 0.2786 (0.2786)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.018 (0.034)	Loss 0.1974 (0.2604)	Prec@1 90.625 (90.551)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.016 (0.025)	Loss 0.1860 (0.2648)	Prec@1 93.750 (91.082)	Prec@5 100.000 (99.962)
Test: [38/40] Acc 91.067
epoch: 39
Train: [0/422]	Time 0.399 (0.399)	Loss 0.2408 (0.2408)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Train: [50/422]	Time 0.063 (0.082)	Loss 0.3457 (0.2375)	Prec@1 82.812 (91.207)	Prec@5 100.000 (100.000)
Train: [100/422]	Time 0.062 (0.070)	Loss 0.2574 (0.2492)	Prec@1 89.062 (90.844)	Prec@5 100.000 (100.000)
Train: [150/422]	Time 0.068 (0.066)	Loss 0.4065 (0.2687)	Prec@1 85.938 (90.094)	Prec@5 100.000 (100.000)
Train: [200/422]	Time 0.070 (0.069)	Loss 0.2382 (0.2680)	Prec@1 92.188 (90.062)	Prec@5 100.000 (99.969)
Train: [250/422]	Time 0.062 (0.070)	Loss 0.2107 (0.2497)	Prec@1 93.750 (90.812)	Prec@5 100.000 (99.953)
Train: [300/422]	Time 0.070 (0.069)	Loss 0.2596 (0.2289)	Prec@1 93.750 (91.562)	Prec@5 100.000 (99.969)
Train: [350/422]	Time 0.071 (0.070)	Loss 0.1522 (0.2304)	Prec@1 93.750 (91.344)	Prec@5 100.000 (99.953)
Train: [400/422]	Time 0.068 (0.072)	Loss 0.1923 (0.2545)	Prec@1 93.750 (90.359)	Prec@5 100.000 (99.938)
Test: [0/47]	Time 0.368 (0.368)	Loss 0.1532 (0.1532)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.014 (0.031)	Loss 0.2343 (0.2451)	Prec@1 89.062 (90.253)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.012 (0.022)	Loss 0.1900 (0.2457)	Prec@1 93.750 (90.854)	Prec@5 100.000 (99.962)
Test: [39/40] Acc 90.833
best ACC: 91.1
